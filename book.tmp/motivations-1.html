<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Chapter 7 Motivations | Nursing School Research Analytics and Computation Report</title>
  <meta name="description" content="This is a summary report of School of Nursing Faculty Interviews">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="Chapter 7 Motivations | Nursing School Research Analytics and Computation Report" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a summary report of School of Nursing Faculty Interviews" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 7 Motivations | Nursing School Research Analytics and Computation Report" />
  
  <meta name="twitter:description" content="This is a summary report of School of Nursing Faculty Interviews" />
  

<meta name="author" content="Steve Pittard">


<meta name="date" content="2019-02-25">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="computation.html">

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />










<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Nell Hodgson Nursing School</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Motivations</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#background"><i class="fa fa-check"></i><b>1.1</b> Background</a><ul>
<li class="chapter" data-level="1.1.1" data-path="index.html"><a href="index.html#the-omics-problem"><i class="fa fa-check"></i><b>1.1.1</b> The “Omics” Problem</a></li>
<li class="chapter" data-level="1.1.2" data-path="index.html"><a href="index.html#the-knowledge-gap---communication-with-cores"><i class="fa fa-check"></i><b>1.1.2</b> The Knowledge Gap - Communication With Cores</a></li>
<li class="chapter" data-level="1.1.3" data-path="index.html"><a href="index.html#data-access-and-collaboration"><i class="fa fa-check"></i><b>1.1.3</b> Data Access and Collaboration</a></li>
<li class="chapter" data-level="1.1.4" data-path="index.html"><a href="index.html#the-promise-of-cloud-computing"><i class="fa fa-check"></i><b>1.1.4</b> The Promise of Cloud Computing</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#executive-summary-and-initial-recommendations"><i class="fa fa-check"></i><b>1.2</b> Executive Summary and Initial Recommendations:</a><ul>
<li class="chapter" data-level="1.2.1" data-path="index.html"><a href="index.html#data-management"><i class="fa fa-check"></i><b>1.2.1</b> <strong>Data management</strong></a></li>
<li class="chapter" data-level="1.2.2" data-path="index.html"><a href="index.html#nursing-centric-analytics-omics-resource"><i class="fa fa-check"></i><b>1.2.2</b> <strong>Nursing-Centric Analytics ‘Omics’ Resource</strong></a></li>
<li class="chapter" data-level="1.2.3" data-path="index.html"><a href="index.html#software-literacy-and-the-curriculum"><i class="fa fa-check"></i><b>1.2.3</b> <strong>Software Literacy And The Curriculum</strong></a></li>
<li class="chapter" data-level="1.2.4" data-path="index.html"><a href="index.html#high-performance-computing"><i class="fa fa-check"></i><b>1.2.4</b> <strong>High Performance Computing</strong></a></li>
<li class="chapter" data-level="1.2.5" data-path="index.html"><a href="index.html#research-desktop-support"><i class="fa fa-check"></i><b>1.2.5</b> <strong>Research Desktop Support</strong></a></li>
<li class="chapter" data-level="1.2.6" data-path="index.html"><a href="index.html#alternatives-to-local-core-processing"><i class="fa fa-check"></i><b>1.2.6</b> <strong>Alternatives to Local Core Processing</strong></a></li>
<li class="chapter" data-level="1.2.7" data-path="index.html"><a href="index.html#student-recruitment"><i class="fa fa-check"></i><b>1.2.7</b> <strong>Student Recruitment</strong></a></li>
<li class="chapter" data-level="1.2.8" data-path="index.html"><a href="index.html#improved-project-logistics"><i class="fa fa-check"></i><b>1.2.8</b> <strong>Improved Project Logistics</strong></a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#the-interview-process"><i class="fa fa-check"></i><b>1.3</b> The Interview Process</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="data-management-1.html"><a href="data-management-1.html"><i class="fa fa-check"></i><b>2</b> Data Management</a><ul>
<li class="chapter" data-level="2.1" data-path="data-management-1.html"><a href="data-management-1.html#data-hosting"><i class="fa fa-check"></i><b>2.1</b> Data Hosting</a></li>
<li class="chapter" data-level="2.2" data-path="data-management-1.html"><a href="data-management-1.html#source-code-maintenance"><i class="fa fa-check"></i><b>2.2</b> Source Code Maintenance</a></li>
<li class="chapter" data-level="2.3" data-path="data-management-1.html"><a href="data-management-1.html#notebooks-and-reproducible-research"><i class="fa fa-check"></i><b>2.3</b> Notebooks and Reproducible Research</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="software-literacy.html"><a href="software-literacy.html"><i class="fa fa-check"></i><b>3</b> Software Literacy</a><ul>
<li class="chapter" data-level="3.1" data-path="software-literacy.html"><a href="software-literacy.html#concerns-about-falling-behind"><i class="fa fa-check"></i><b>3.1</b> Concerns About Falling Behind</a></li>
<li class="chapter" data-level="3.2" data-path="software-literacy.html"><a href="software-literacy.html#workshops"><i class="fa fa-check"></i><b>3.2</b> Workshops</a></li>
<li class="chapter" data-level="3.3" data-path="software-literacy.html"><a href="software-literacy.html#sasspss-vs-open-source-tools"><i class="fa fa-check"></i><b>3.3</b> SAS/SPSS vs Open Source Tools</a></li>
<li class="chapter" data-level="3.4" data-path="software-literacy.html"><a href="software-literacy.html#attracting-software-literate-students"><i class="fa fa-check"></i><b>3.4</b> Attracting Software Literate Students</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="interaction-with-cores.html"><a href="interaction-with-cores.html"><i class="fa fa-check"></i><b>4</b> Interaction with Cores</a><ul>
<li class="chapter" data-level="4.1" data-path="interaction-with-cores.html"><a href="interaction-with-cores.html#expectations-of-cores"><i class="fa fa-check"></i><b>4.1</b> Expectations of Cores</a></li>
<li class="chapter" data-level="4.2" data-path="interaction-with-cores.html"><a href="interaction-with-cores.html#understanding-results"><i class="fa fa-check"></i><b>4.2</b> Understanding Results</a></li>
<li class="chapter" data-level="4.3" data-path="interaction-with-cores.html"><a href="interaction-with-cores.html#need-for-more-consultation"><i class="fa fa-check"></i><b>4.3</b> Need for More Consultation</a></li>
<li class="chapter" data-level="4.4" data-path="interaction-with-cores.html"><a href="interaction-with-cores.html#possible-solutions"><i class="fa fa-check"></i><b>4.4</b> Possible Solutions</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="project-initiation-dynamics.html"><a href="project-initiation-dynamics.html"><i class="fa fa-check"></i><b>5</b> Project Initiation Dynamics</a><ul>
<li class="chapter" data-level="5.1" data-path="project-initiation-dynamics.html"><a href="project-initiation-dynamics.html#continuity-throughout-the-research-process"><i class="fa fa-check"></i><b>5.1</b> Continuity Throughout the Research Process</a></li>
<li class="chapter" data-level="5.2" data-path="project-initiation-dynamics.html"><a href="project-initiation-dynamics.html#estimating-effort"><i class="fa fa-check"></i><b>5.2</b> Estimating Effort</a></li>
<li class="chapter" data-level="5.3" data-path="project-initiation-dynamics.html"><a href="project-initiation-dynamics.html#grants"><i class="fa fa-check"></i><b>5.3</b> Grants</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="computation.html"><a href="computation.html"><i class="fa fa-check"></i><b>6</b> Computation</a><ul>
<li class="chapter" data-level="6.1" data-path="computation.html"><a href="computation.html#data-management-and-computation"><i class="fa fa-check"></i><b>6.1</b> Data Management and Computation</a></li>
<li class="chapter" data-level="6.2" data-path="computation.html"><a href="computation.html#cloud-vs-local-resources"><i class="fa fa-check"></i><b>6.2</b> Cloud vs Local Resources</a><ul>
<li class="chapter" data-level="6.2.1" data-path="computation.html"><a href="computation.html#onboarding-cloud-support"><i class="fa fa-check"></i><b>6.2.1</b> Onboarding Cloud Support</a></li>
<li class="chapter" data-level="6.2.2" data-path="computation.html"><a href="computation.html#post-project-data-archival"><i class="fa fa-check"></i><b>6.2.2</b> Post Project Data Archival</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="computation.html"><a href="computation.html#desktop-support-for-open-source-analysis-tools"><i class="fa fa-check"></i><b>6.3</b> Desktop Support for Open Source Analysis Tools</a></li>
<li class="chapter" data-level="6.4" data-path="computation.html"><a href="computation.html#general-it-support"><i class="fa fa-check"></i><b>6.4</b> General IT Support</a></li>
<li class="chapter" data-level="6.5" data-path="computation.html"><a href="computation.html#databases-and-applications"><i class="fa fa-check"></i><b>6.5</b> Databases and Applications</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="motivations-1.html"><a href="motivations-1.html"><i class="fa fa-check"></i><b>7</b> Motivations</a><ul>
<li class="chapter" data-level="7.1" data-path="motivations-1.html"><a href="motivations-1.html#background-1"><i class="fa fa-check"></i><b>7.1</b> Background</a></li>
<li class="chapter" data-level="7.2" data-path="motivations-1.html"><a href="motivations-1.html#the-interview-process-1"><i class="fa fa-check"></i><b>7.2</b> The Interview Process</a></li>
<li class="chapter" data-level="7.3" data-path="motivations-1.html"><a href="motivations-1.html#executive-summary-and-initial-recommendations-1"><i class="fa fa-check"></i><b>7.3</b> Executive Summary and Initial Recommendations:</a><ul>
<li class="chapter" data-level="7.3.1" data-path="motivations-1.html"><a href="motivations-1.html#data-hosting-and-management"><i class="fa fa-check"></i><b>7.3.1</b> <strong>Data Hosting and Management</strong></a></li>
<li class="chapter" data-level="7.3.2" data-path="motivations-1.html"><a href="motivations-1.html#hercules-data-science-resource"><i class="fa fa-check"></i><b>7.3.2</b> <strong>HERCULES Data Science Resource</strong></a></li>
<li class="chapter" data-level="7.3.3" data-path="motivations-1.html"><a href="motivations-1.html#software-literacy-1"><i class="fa fa-check"></i><b>7.3.3</b> <strong>Software Literacy</strong></a></li>
<li class="chapter" data-level="7.3.4" data-path="motivations-1.html"><a href="motivations-1.html#pilot-project-initiation-logistics"><i class="fa fa-check"></i><b>7.3.4</b> <strong>Pilot Project Initiation Logistics</strong></a></li>
<li class="chapter" data-level="7.3.5" data-path="motivations-1.html"><a href="motivations-1.html#the-omics-problem-1"><i class="fa fa-check"></i><b>7.3.5</b> The “Omics” Problem</a></li>
<li class="chapter" data-level="7.3.6" data-path="motivations-1.html"><a href="motivations-1.html#the-promise-of-cloud-computing-1"><i class="fa fa-check"></i><b>7.3.6</b> The Promise of Cloud Computing</a></li>
<li class="chapter" data-level="7.3.7" data-path="motivations-1.html"><a href="motivations-1.html#high-performance-computing-1"><i class="fa fa-check"></i><b>7.3.7</b> <strong>High Performance Computing</strong></a></li>
<li class="chapter" data-level="7.3.8" data-path="motivations-1.html"><a href="motivations-1.html#research-desktop-support-1"><i class="fa fa-check"></i><b>7.3.8</b> <strong>Research Desktop Support</strong></a></li>
<li class="chapter" data-level="7.3.9" data-path="motivations-1.html"><a href="motivations-1.html#alternatives-to-local-core-processing-1"><i class="fa fa-check"></i><b>7.3.9</b> <strong>Alternatives to Local Core Processing</strong></a></li>
<li class="chapter" data-level="7.3.10" data-path="motivations-1.html"><a href="motivations-1.html#student-recruitment-1"><i class="fa fa-check"></i><b>7.3.10</b> <strong>Student Recruitment</strong></a></li>
<li class="chapter" data-level="7.3.11" data-path="motivations-1.html"><a href="motivations-1.html#improved-project-logistics-1"><i class="fa fa-check"></i><b>7.3.11</b> <strong>Improved Project Logistics</strong></a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Nursing School Research Analytics and Computation Report</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="motivations-1" class="section level1">
<h1><span class="header-section-number">Chapter 7</span> Motivations</h1>
<div id="background-1" class="section level2">
<h2><span class="header-section-number">7.1</span> Background</h2>
<p>The original scope of this report was focused on understanding the research being proposed and conducted by HERCULES affiliated investigators. However, it became apparent that there was as much concern about how the underlying institutional and school infrastructure has been architected (or not) to faciliate data aquisition, management, analysis, and the reproducibility of research results. Associated issues relate to interactions with Core facilities, software literacy and generally how investigators should prepare themselves and their teams to better manipulate data, as well as the results emanating from Core facilities, which increasingly requires greater facility with the UNIX command line as well as software pipelines based on R, Python, and databases (both relational and noSQL). Having convienent access to one’s data is important and, while the promise of an institutional cloud computing environment is very appealing, most investigators have only a superficial idea about how one would fully exploit such services and how to effectively write these resources into grant proposals.</p>
</div>
<div id="the-interview-process-1" class="section level2">
<h2><span class="header-section-number">7.2</span> The Interview Process</h2>
<p>Conducting these interviews was a smooth process as those contacted were very forthcoming with helpful responses that were consistent across the topic areas described in this report. Everyone was collegial and supplied viewpoints that will generally benefit the HERCULES Center as a whole. Everyone seems to be aware that Pilot grants need to lay the ground work for successful grant applications both for the benefit of the investiator’s career and in support of Center aims. The interview list included Carmen Marsit, Amber Burt, Stefanie Sarnat, Howard Chang, Dayna Johnson, Michelle Kegler, Melanie Pearson, Eberhard Voit, Eddie Morgan, Donghai Liang, and Yang Liu.</p>
</div>
<div id="executive-summary-and-initial-recommendations-1" class="section level2">
<h2><span class="header-section-number">7.3</span> Executive Summary and Initial Recommendations:</h2>
<p>Note that these suggestions represent starting points which can flexibly be implemented in a standalone fashion although an integrated approach with other HERCULES initiatives and/or those at the institutional level should be considered - particularly in conjunction with the School of Nursing. Most, if not all, of these recommendations are motivated by direct suggestions from faculty who have attempted to address these problems in various ways including leveraging personal, professional, and external relationships. Further discussion is warranted particularly on items relating to the formation of a Data Science support resource and the possible licensing of a data management and computation framework such as DNANexus.</p>
<div id="data-hosting-and-management" class="section level3">
<h3><span class="header-section-number">7.3.1</span> <strong>Data Hosting and Management</strong></h3>
<blockquote>
<p>The Center should consider use of a framework for data hosting and management which could provide a central staging area for data with the added benefot of being co-located in proximity to computational resources. Ideally, the institution would provide subsidized S3 access commensurate to that which is currently provided to Emory Box</p>
</blockquote>
<p>Data hosting and accessibility are very important aspects of research although the current practices for supporting these activities are less than ideal. There are currently three Emory storage solutions (Isilon, Box, and Amazon) and the use cases for each are not always clear to researchers. The reference data copies for many projects reside in Emory Box from which multiple copies are “fanned out” based on the number of participants in the research project. Because of this, intermediate or final results and associated code are usually not reintegrated alongside the original data which impairs reproducibility. Unfortunately, Emory Box cannot be computed against though it is free which is why it has become the default repository for many faculty. To reduce confusion and to provide computational “elbow room”, the Center should consider a framework for data management would be helpful for the organization of Center information.</p>
<p>This could take several forms with the most basic being adoption of Amazon S3 storage as a default hosting solution for Center sponsored data. <strong>Ideally, the institution would provide subsidized S3 access commensurate to that which is currently provided to Emory Box</strong>. This would 1) encourage adoption of cloud computing which is a stated institutional aim already and 2) increase the likelihood of adoption of cloud computing by investigators since their datq is in close proximity to compute resources. Using Amazon S3 (or Google storage) is useful because it is a highly available and reliable object store that allows for intutitive partitioning according to business unit, type, and application. Accessing this storage from other Amazon (or Google) resources is easy and well integrated into the entire suit of services on offer. Simply stockpiling data in one spot, while a step in the right direction, would not immediately result in scientific insight thus some awareness of how it is organized is required to animate it.</p>
<blockquote>
<p>The Center should also consider use of a tool such as DNANexus or Seven Bridges Genomics. either of which would provide comprehensive support for managing sequencing-based projects, analytics, as well as the convenient addition of self-developed pipelines.</p>
</blockquote>
<p>Another approach, currently under consideration by both Winship Cancer and The School of Nursing, involves the use of an integrated data managment and computation tool such as <a href="https://www.dnanexus.com/">DNANexus</a> which leverages Amazon computer and storage while providing open support for aggressive biomedical analytic pipelines. The product also provides extensive support for individual organizations either separately or hierarchically to make billing and data management transparent. This would address a number of concerns of having “everything in one place” (to the extent that it is possible) along with computational results in a format that would enable reproducibility. Additionally, a solution such as DNANexus would facilitate the integration of genomic data with clinical and other phenotypic data in a secure and compliant environment. While RedCap is useful for maintaining study information, being able to link in sequencing and sample information can be challenging.</p>
<div id="project-contuniuty-and-the-role-of-the-data-manager" class="section level4">
<h4><span class="header-section-number">7.3.1.1</span> Project Contuniuty and The Role of The Data Manager</h4>
<p>The interviews led to a greater awareness of the growing importance of the “Data Manager”. It is generally understood that a Data Manager should be adept at the collection, validation, cleaning, and management of data in anticipation of downstream analysis. However, there is a growing reliance on that role to provide interpretation services and become familar with experimental technologies simply because these individuals are closer to the data, and coding necessary to analyze it, more so than the investigator. In effect the data manager becomes the de facto informatics representative and thus occupies a larger role than simple data management. This isn’t necessarily a problem until the person departs which is not uncommon in grant funded positions. Such departures intefere with progress and reproducibility especially when project documentation is lost or has been informally maintained. Use of coding repositories such as <a href="https://github.com/">Github</a> are a function of a given lab and there is wide variation in how (or if) labs maintain software notebooks. This is of concern given that data can occupy multiple locations throughout the project trajectory as can the code used to transform that data, thus some attempt at offering a unifed architecutre is important. Departures of key personnel lead to a significant loss of productivity and overall project knowledge, at least from a technical point of view, that has to be rebuilt when new personnel arrives. While this is a common problem in computationally-based research perhaps the Center can mitigate these departures by offerring some assistance at the Center level.</p>
</div>
<div id="the-role-of-the-data-lake" class="section level4">
<h4><span class="header-section-number">7.3.1.2</span> The Role of the Data Lake</h4>
<p>The cumulative storage needs of the known HERCULES pilot projects are manageable at the terabyte level although investigators frequently relocate data to perform computation and analysis which, depending on the location (desktop or cluster) can encounter storage limits. Investigators would like to “stretch out” without concern of using “too much” space though the greater priority is having access to a well supported computational environment in conjunction with a <strong>base</strong> for data that does not require relocation or duplication simply to enable collaboration. Attempting to compute at the desktop level has been problematic for most investigators due to the restrictive polices on desktop software installations. HERCULES projects, taken as a whole, involve a mixture of data types including PDFs, spreadhseets, SAS Data sets, CSV, accelermoter, pollution count, sequencing, and experimental data types. While this seems challenging to accomodate as a unified collection it is better to view this as a “Data Lake”&quot; which supports the co-existence of heterogenous data types in a way that enables “query on demand” for purposes of exploration.</p>
<p>With Data Lakes, no initial effort is made to impose an enforced, relational structure onto the body of data in anticipation of tradtional transactional analytics activity. First, those efforts assume a well-ordered set of data though, taken as a whole, much of the HERCULES data is not of this type. Second, large scale interrogations might not happen at a level that justifies the initial effort required to create the data warehouse. Some of the more structured data could be hosted in Redcap but most of the data currently under consideration is unstructured or semi-structured which might be better addresed using noSQL “databases” and “query on demand” tools. Thus, based on the interviwes, adopting a schema-less approach is reasonable as long as researchers have ready access to the information as a unit and also have some understanding of how to query for exploration and hypothesis generation. For example the sleep study data which is part of Dayna Johnon’s project involves air quality data alongside acceleromter data which will require co-analysis that would otherwise be difficult if the data is located in multiple places. For explotatory purposes it is relatively straight forward to create a temporary “projection” onto the larger data that yields preliminary results rather than first creating a relational schema to house the data. Obviously, investigators will use known methods and packages to conduct analysis though services auch as Amazon Athena (which uses open source approaches underneath the hood) are excellent tools for accomplishing “data spelunking” at preliminary levels.</p>
</div>
</div>
<div id="hercules-data-science-resource" class="section level3">
<h3><span class="header-section-number">7.3.2</span> <strong>HERCULES Data Science Resource</strong></h3>
<blockquote>
<p>The formation of a Data Scidence support group is recommended. Such a group improve the working dynamic since HERCULES investigators would have an advocate acting on their behalf both at the Pilot stage and as progress reports are developed. This would not replace or diminish the relationships with existing University Cores but rather supplement them.</p>
</blockquote>
<p>Availability of professionals who understand the analytics, statistics, and omics aspects of HERCULES sponsored projects is important though such resources require funding. <strong>To this end, the formation of a HERCULES support group is recommended</strong>. It would provide services for analytics, computing, and data management. Another role would be to organize training and providing orientation for the framework mentioned in item #1. The idea is not to mask problems that might exist at the Core level or relieve investigators of the responsibility to cultivate informatics skills within their own lab. In fact, to be successful, any support group or Core will require a motivated representative from the respective labs to facilitate progress. Specifically, the support group is not desgined to be a “drop off” analysis service that anticipates any and all problems associated with the project and performs corrective action. Although being able to first identify and address some of the more obvious problems is a primary goal to keep projects on track and in a better position to win grant funding. Whether this support group is an “official university core” or a group local to the Center is up for debate although the interviews reveal a gap between what labs can do for themselves particualrly related to informatics and comprehension of newer experiemental data types. Equally as important is the is idea that such a resource could be referenced in applications for grants involving large scale processing. This would be evidence of a formal institutional commitment to Center aims. Opinions vary as to the exact composition of this group and/or if it should draw from existing personnel (who aren’t already fully funded). However, it was generally agreed that having more domain specific expertise available specifically for the Center would not be a bad idea.</p>
<div id="the-knowledge-gap---communication-with-cores-1" class="section level4">
<h4><span class="header-section-number">7.3.2.1</span> The Knowledge Gap - Communication With Cores</h4>
<p>Core facilities, both local and external, are challenged to produce actionable results at a reasonable cost though clients of these facilities (Microbiome and Metabolomics in particular) typically want more in terms of explanation and follow up support as they progress towards publishable conclusions. While most of those interviwed felt comfortable with Core results being returned from Cores, some had yet to fully engage these services so could not comment on the experience. One investigator, Donghai Linag, reports satisfaction with the Metabolomics core though points out that he has worked extensively with this type of data during his Post doc experience so he has perspecgive that others do not. Non coincidentally, he is asked to assist with questions about metabolomics data and while he is willing to help he is increasingly engaged with his new duties. Emory Cores typically offer transaction-based services by design although users frequently want an additional period during which they can ask questions and request alternative results based on their understanding of the experiment at hand. The Cores generally do not have the personnel or time to offer this which has produced something of a gap that is usually addressed by drafting in resources from sources such as post docs, Georgia Tech students, collaborators and peers at other institutions. Addressing this gap involves a combination of activities involving the development of domain expertise by investigators (or their proxy) along with greater willingness by the Cores to treat engagements holistically as opposed to “one-and-done” transactions. This is why HERCULES should consider the formation of a data science support group to perform the necesary triage and handoffs between the group. Note that this support group isn’t intended to be a “drop off” service that insulates investigators from the realities of data analysis and Core products but rather a junction point where concerns can be captured and addressed according to Center priorities and resources.</p>
</div>
</div>
<div id="software-literacy-1" class="section level3">
<h3><span class="header-section-number">7.3.3</span> <strong>Software Literacy</strong></h3>
<blockquote>
<p>Improving general <strong>software literacy</strong> is essential as is being able to import/transform data, accomplish analytic tasks, create plots, query databases, and create digital assets. There is currently a gap in knowledge that should be addressed via a combination of formal courses and shorter, more focused types of education.</p>
</blockquote>
<p>The paper <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4101704/">“Data integration in the era of omics: current and future challenges”</a> discusses the idea that bioinformaticians are drawn from two distinct domains: 1) those who emerging from a computer science or mathematics background who have learned enough about biology to be helpful or 2) trained biologists who, of necessity, have acquired a knowledge of programming to approach their data. While this is an organic pattern that will likely continue it is generally agreed that a redevelopment of teaching practices that favor inter-disciplinary involvement is essential to produce computer savvy investigators.</p>
<p>Many faculty pursue self-education but are interested in becoming much more self-sufficient with open source tools and the UNIX command line. This can be accomplished via participation in the Big Data course or more specific classes. A larger issue relates to what extent the Cores and LITS are interested in educating users, respectively, on domain specific pipelines and cloud computing ? Or, is it incumbent on the investigator to develop a team to ensure productivity ? Amazon presents a steep learning curve as can understanding results being returned from Cores. Some level of shared responsibility must be assumed in the development of final results. Part of the research process does involve self-education and a willingness to take a deep dive when attempting to adapt literature-based methods to local projects. Software literacy helps provide a common language and vocabulary for research.</p>
<p>At this point, both students and faculty would benefit from courses that discuss and require the integration of computation, data, alongside with prototypical research challenges common to Nursing-based investigations. The path to such courses is relatively clear in terms of what is needed though there should be sufficient funding and lead time for development. The nature of these courses could be divided into two related areas: 1) Introductory material relating to the mechanics of UNIX command line, basic programming, data management, and cloud access 2) Applied courses that assume some level of software literacy.</p>
<p>In terms of informal education one excellent (and cheap) resource is to arrange for an onsite <a href="https://software-carpentry.org/">Software Carpentry</a> session which is a 1 to 3 day workshop devoted to teaching basic lab skills for research computing. These sessions are professionally taught and include hands on labs to learn the UNIX command line, R and Python Programming, Git, SQL and Databases. These are targeted to the novice but would also serve to reinforce skills. The material is open source and maintained on GitHub so we could possibly offer the course material with local teaching resources. The following graph illustrates the motivation levels for various software and command line topics after taking a Core level Software Carpentry class.</p>
<div class="figure">
<img src="PICS/carpentry.png" width="550" />

</div>
</div>
<div id="pilot-project-initiation-logistics" class="section level3">
<h3><span class="header-section-number">7.3.4</span> <strong>Pilot Project Initiation Logistics</strong></h3>
<blockquote>
<p>To optimize resources available for Pilot Projects, the Center should demonstrate specific awareness of costs for supporting technologies in applications.</p>
</blockquote>
<p>The Center already provides up front consultation for investigators seeking Pilot support. However, it is fair to say that research involves some level of uncertainty especially and it is only after the project has been initiated that the need for additional resoures will be necessary. However, effective up front planning can reduce this gap. The Center, of course, would like to see the Pilot projects evolve into successful grant applications thus there is pressure to get estimates and resources correctly identified up front. The investigator must “have skin” in this process which means that planning for Pilots should be a collaborative engagement wherein the investigator brings their expertise and awareness of appropriate costs (for Core services as an example) which can be refined and supplemented with Center guidance. This also simplifies the job of the Communication Core who wishes to offer periodic updates to HERCULES stakeholders. At a functional level, the development and implementation of a common logistical workflow would be helpful to guide faculty and doctoral students throughout the project life cycle. This is particularly true when documenting required personnel, appropriate percent effort, and anticipated service core involvement.</p>
<p>It is not surprising that many investigators rely upon student labor to accomplish their work though there is a sense that the technical and analytic demands of the work has led to a gap in terms of software literacy when considering hogh throughput data. For example,</p>
<p>Some faculty do use R Notebooks for reproducibility but point to the problem of keeping track of results generated by others who might “touch”&quot; the project and preserve their own scripts and transformed data on their laptop. Given that shuffling data around is largely a manual process, trying to “work back” from results to the original data is challenging.</p>
<p>This extends to the concept of desktop control in that most of those itnterviewed feel constrained by restrictive polcies that prevent the convenient installation of common opensource tools (or even a new version of a browser) without having to contact someone for assistance. It is agreed that the institution should apply rigorous security data policies but not in a way that impairs reasonable access paths to that information. Using or invoking the general concept of security to not provide assistance seems to be a default practice though investigators would like to see a more nuanced approach to the application of security that recognizes levels of security.</p>
</div>
<div id="the-omics-problem-1" class="section level3">
<h3><span class="header-section-number">7.3.5</span> The “Omics” Problem</h3>
<p>The magnitude and highly dynamic nature of omics-based projects can lead to interesting explorations though ultimately the research should lead to publications in high impact journals and successful grant applications. These goals, however, can be frustrated by uncertainty about how best to manage data, which analytic techniques are most appropriate, where the computation should be performed, and how to effectively determine the biological relevance of the result. This can also be particularly challenging for doctoral students who can sometimes receive conflicting advice on how to structure omics-based thesis projects. Creating smooth workflows using omics-data is essential to progress and publications thus strategies must be developed to effectively deal with this situation.</p>
</div>
<div id="the-promise-of-cloud-computing-1" class="section level3">
<h3><span class="header-section-number">7.3.6</span> The Promise of Cloud Computing</h3>
<p>Cloud computing offers unprecedented access to scaleable, on-demand computation and storage resources in a manner that allows Emory researchers to be competitive with institutions that possess much larger and far more extensive on-premise computational infrastructure. In effect, services such as Amazon and Google democratize computing by enabling access to anyone with a credit card and a willingness to learn how to leverage the environment. However, the path to productivity is not always clear and there is confusion on how to approach Amazon services even before considering how to execute at-scale bioinformatics jobs and pipelines. The language of Amazon is one of enterprise services and architecture as opposed to research computing so educational material, even at the instituional level, generally describes services at a very high level when what is needed are practical workshops for learning how to leverage the strength of Amazon and Google. The Emory LITS organization is in the process of rolling out a solution (ETA 2019) to help researchers but the larger question relates to what extent the cloud team will provide “in the trenches”, hands on training and help with selecting and managing various instance types, storage resources, and databases above and beyond the architectural level.</p>
</div>
<div id="high-performance-computing-1" class="section level3">
<h3><span class="header-section-number">7.3.7</span> <strong>High Performance Computing</strong></h3>
<blockquote>
<p>The School should identify paths to cloud and command-line literacy via courses and training developed internally and in conjunction with Amazon Web Services.</p>
</blockquote>
<p>Research is increasingly reliant upon both desktop and high performance computation thus a commensurate level of support is needed. Computation remains a challenge in that the School does not currently “own” any significant computational resources which has led researchers to leverage personal and external professional relationships to accomplish work. This does not scale at all. Facility with cloud computing is a challenge even for those who are computationally aware thus for newcomers it is especially so. It is not currently clear to what extent LITS or existing Cores will help researchers address the skills gap or is it expected for investigators to self-educate and recruit students to handle computational aspects of their projects. Independently of from whom the help comes, the faculty were quite clear in their interest and desire for more assistance and training.</p>
<p>If the School does <strong>NOT</strong> pursue a Nursing Centric resource then cloud education will be a function of informal resources and/or funded personnel specific to individual projects vis-a-vis a percent effort model. However, this does little to raise the general computational awareness at the School level. It would be useful for the LITS cloud team or Core facilities to offer ongoing orientation and support for adopting cloud resources along with expertise in system administration, package installation, database loading (both noSQL and SQL), programming (R, Python), and other services common to biomedical and bioinformatics projects. This includes agile and flexible support for opensource tools above and beyond standard enterprise tools. In absence of such help, the School of Nursing will have to develop internal resources which of course might even be preferable. In any case, the knowledge gap must be addressed.</p>
<p>A secondary approach to the computation issue might involve partnering with the Department of Biomedical Informatics which maintains a sophisticated, well-functioning, well-supported computational cluster dedicated to aggressive research computing. This would have to be arranged but none of the projects currently being considered within the School of Nursing would represent a challenge to that environment. BMI would be an appropriate partner because research computing is “baked-in” to their mission and is thus seen as an essential service for researchers. I discussed a potential relationship with Jim Kinney (BMI System Lead) earlier this year but would need to renew those talks.</p>
</div>
<div id="research-desktop-support-1" class="section level3">
<h3><span class="header-section-number">7.3.8</span> <strong>Research Desktop Support</strong></h3>
<blockquote>
<p>Nursing School resesrchers want a higher degree of “research aware” desktop support services from Nursing IT.</p>
</blockquote>
<p>While learning more about Amazon is important, all of the faculty interviewed have expressed disappointment with current School IT support which, as a group, does not seem motivated or interested in helping staff, students, or faculty particularly as it relates to research. Nursing School researchers need desktop assistance particularly as it relates to installing, updating, and running opensource packages such as R, Python, Anaconda and associated opensource tools. The School faculty should not expect IT personnel to actively conduct research or understand the intricacies of software workflows. However, the IT group should be able to troubleshoot package installation conflicts, prerequisites, and perform upgrades necessary to enable base level research exploration. In general most faculty believe that Nursing IT should be incentivized to more aggressively support research including a basic level of cloud orientation. The fact that the IT group is currently not oriented towards such activities should be not an ongoing rationale to keep the status quo. Lastly, it is clear that Nursing IT has unique challenges that for the most part warrant separate consideration from research computation. That is, <strong>it is not advisable to create a merged or combined group under the IT flag since research computation has both technical and personnel needs that require guidance by scientifically oriented leadership</strong>. While it might be tempting to generically group everything relating to technical needs under one group such an action would short-change the interests of both groups. The recruitment of highly-skilled analytics and computational personnel is a challenge deserving of a standalone organizational structure.</p>
</div>
<div id="alternatives-to-local-core-processing-1" class="section level3">
<h3><span class="header-section-number">7.3.9</span> <strong>Alternatives to Local Core Processing</strong></h3>
<blockquote>
<p>The School should develop relationships with trusted external scientific resource providers to process urgent requests for sample processing and analysis consultation.</p>
</blockquote>
<p>This should also include training resources which could be accomplished virtually, on-premise (for larger groups), or remotely. Even if all concerns with local Cores are fully addressed there remains a need for expedited processing and domain specific expertise to address backlogged projects or efforts requiring special care during processing. Not every project will require this but there should be a reliable outlet for “blocked” projects or those requiring a rapid turnaround. In particular, we should organize training to learn “best practices” in the processing and analysis of Microbiome and Metabolomics. At least one faculty member has used an external lab for Microbiome and another is contemplating the re-sequencing of a large number of samples via the Ravel Lab at the Institute of Genome Sciences to obtain domain expertise starting at the sequencing level.</p>
</div>
<div id="student-recruitment-1" class="section level3">
<h3><span class="header-section-number">7.3.10</span> <strong>Student Recruitment</strong></h3>
<blockquote>
<p>Deliberate efforts should be made to recruit graduate students with ability and/or interest in data manipulation and analysis since the nature of research within the school will require such a background.</p>
</blockquote>
<p>It is difficult to imagine a scenario wherein a graduate student could be successful without acquiring at least a basic fluency with these tools. Obviously, such skill can be developed over time though biomedical research assumes that students can clean, reshape, and transform data both prior to analysis and afterwards. While no one believes that using <strong>only</strong> student “labor” to accomplish projects is reasonable, there is a goal of having software literate students who can “dive in” to projects. However, the School Dean did express a specific concern that it can be challenging for doctoral students who sometimes receive conflicting advice on how to structure omics-based thesis projects. So while having software savvy students is a plus, they will still require guidance in the selection and execution of their thesis work which in turn assumes the existence of a knowledgeable supportive community. For better or worse, the domain of biomedical, bioinformatics, and nursing research requires a base level of quantitative skill and facility with software packages such as R, Python, and various open source tools.</p>
</div>
<div id="improved-project-logistics-1" class="section level3">
<h3><span class="header-section-number">7.3.11</span> <strong>Improved Project Logistics</strong></h3>
<blockquote>
<p>Faculty want access to personnel familiar with the statistics, computation, and bioinformatics as part of the research planning phase. This could be part of the previously mentioned Data Science resource or independent of it.</p>
</blockquote>
<p>Researchers would like more detailed upfront estimates of statistics, analytics, and computation costs to better project cost of staff involvement. Not knowing how much (in time, money, and personnel) the key aspects of a project will “really” involve is a concern. This could be implemented separately of the proposed local Nursing Omics resource though if such a resource did exist then this person could also be part of that that. The overall idea is to have accurate and reliable estimates of sequencing, analytics, and computation work. Some junior faculty feel that they cannot fully access personnel due to lack of funding or because the more experienced personnel are already mostly engaged on other projects. In general, having a standard logistical workflow that specifies who to involve, when, and to what extent is needed. This includes collaborating domain expertise (statistics and bioinformatics personnel) as well as key Core facilities - internal or external to Emory.</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="computation.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": ["Nursing Report.pdf", "Nursing Report.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>
