[
["index.html", "Intro To Research Computing Chapter 1 Computation In Research 1.1 What Do the Top Sites Use ? 1.2 Division of Labor 1.3 Popular Data Science Languages 1.4 Is Windows Good For Computation ? 1.5 What’s Wrong with Windows ? 1.6 Is There a Middle Ground ? 1.7 Apple OSX / macOS ?", " Intro To Research Computing Steve Pittard 2019-04-03 Chapter 1 Computation In Research Biomedical and Public Health Research is increasingly reliant upon computation to achieve its aims. There are a number of considerations to make when thinking about how best to conduct computationally-assisted work. This also includes ideas on how to develop, maintain, and implement software pipelines. When doing literature reviews it is increasingly common to see references to programs written in R, Python, Java as associations with databases, REST APIs, and various cloud architectures. What this means is that it is incumbent upon researchers to learn something about analytics tools and supporting development languages to be competitive. Hopefully, this information can clear up some confusion and provide some basic ideas on how to be productive. Summary: Linux and UNIX (considered here as one in the same although technically that’s not true) has the largest market share by far when considering computational research. If you intend on pursing research and want to use computation at scale then Linux is the way to go. You can still use OSX or Windows as a way to access Linux servers or you could use a Linux desktop. We’ll learn about accessing remote LINUX servers and cloud instances. It’s always helpful to understand the trends to see where things are going. At one time most of the world’s computing took place on privately owned resources. It turns out that that is still the case. Check out the following: 1.1 What Do the Top Sites Use ? If you are fortunate then you have access to a professionally maintained computational cluster that has all the packages and languages you need along with a highly responsive staff who will answer questions for you and provide assistance in the design of large scale runs. Most people do not have access to such resources or if they do it is basic access to a cluster with little or no add on support. It depends on your department and institution. Consider the site Top 500 website whose mission is to provide information on the Top 500 most significant computational installations in the world. This is important not just from an enthusiast or geek point of view but as an indicator of what it takes to support aggressive types of computational research. Statistics on high-performance computers are of major interest to manufacturers, users, and potential users. These people wish to know not only the number of systems installed, but also the location of the various supercomputers within the high-performance computing community and the applications for which a computer system is being used. Such statistics can facilitate the establishment of collaborations, the exchange of data and software, and provide a better understanding of the high-performance computer market. 1.2 Division of Labor There is a natural tendency to use one’s laptop or desktop computer to do some analysis which, in a general sense, is okay. This can be very useful for learning a particular approach or becoming familiar with a package you read about in a research paper. The laptop can also be a great place to work on creating prototypical applications that are modest in size with the idea of eventually moving them to larger infrastructure for scaling. 1.2.1 Mixing Work and Pleasure When getting a desktop or laptop everyone starts out with the best of intentions by wanting to devote the computer to a specific set of tasks. Although over time the laptop becomes a mixture of work and pleasure along with some activities that involve both. If you organize your hard drive well then you can easily make distinctions between personal and work data but eventually it becomes unclear as to what is what. Also keep in mind that most laptops and desktops are configured and optimized to support general office productivity such as accessing the Internet, reading E-Mail, and preparing documents. One can also install applications such as SAS, SPSS, or R-Studio to do some analysis and if the size of the input data is manageable then this is fine. 1.2.2 Mixing E-Mail and Research ? The trouble starts when you have to install tools that require additional configuration or adjustments to system permissions which might then impact other programs on the system. Usually this isn’t the case but I’ve filled up my hard drive with data files on a system that is ostensibly for personal productivity. So not only does the system become unwieldy for analysis but then I have no room for my office stuff. Let’s put it another way, you do not want to be doing serious research and computation on the same computer you normally read e-mail on. I’ve seen people trying to open e-mail attachments that causes the system to reboot thus destroying a long running process. 1.2.3 You’ll Do It Anyway The lesson here is that once you hit a certain threshold of analytics activity or start managing large data sets that gobble up most of you hard drive then it’s reasonable to consider using a server or external computer that is optimized for analysis and data storage. At a minimum, you should move your data files over to a shared drive (if one is available) and refer to that location when doing work. Obviously, when going home you will need to make local copies or use the VPN to attach to the shared drive from home. 1.3 Popular Data Science Languages Let’s take a look at one survey that rates the most popular languages and frameworks used in Data Science. This is from the KDNuggets website. These aren’t the only languages and there are some languages like Julia that are gaining some market share. The way to think about lists like this is that if you need a lot of these then you are probably heading in a direction that would benefit from using a Linux based server or a virtual machine or Docker of some type. Especially if you have lots of data to clean and transform. But you could install most of these tools on a laptop running Windows or OSX. Also remember that you would also use things like SAS, SPSS, Systat, Minitab, etc. 1.4 Is Windows Good For Computation ? The Windows Operating System has a rich history as a desktop operating system for consumer level activity but this does not then mean that it’s the best platform for accomplishing research. Most of the personal computers and laptops sold today come with some version of Windows which then implies that most people have will have a degree of familiarity with it. You can also install things like SAS, SPSS, Systat but those are also available on Mac OS which we will get to soon enough. 1.5 What’s Wrong with Windows ? Nothing - as long as you like getting viruses and having to install a never ending series of software updates that seem to only compound the very problems that the updates alleged to address in the first place. For many people, it’s a fine Operating System for general office productivity. Information Technology managers LOVE it because it’s what “everyone else uses” even if that’s not a particularly good reason to do something. 1.5.1 Windows Security, Virus, and Performance Issues Do I REALLY need to convince you of this ? Windows has many security and virus problems to the extent that you MUST have Anti Virus tools installed that itself frequently prevents the installation of packages. Lots of IT managers will deprive the user of management permissions which requires the user to then go get help simply to install a package or tool. Default permissions are usually set to prevent most anything from being installed to make administration easier. There are some good IT people and I’m speaking in general here. It’s just that the typical Windows support person does not have a research or computation background so their interest in helping is probably going to be restricted to the “bread and butter” activities such as keeping the system healthy for running other MS products, accessing the web, email and calendering. On the other hand that should tell you everything you need to know - that industry and academia tend to view MS Windows as an office productivity setup so they rarely devote research support resources (but they should offer reasonable alternatives). 1.5.2 Windows Reboots and Updates Have you ever encountered the Windows Update screen that holds your computer captive, sometimes for hours, to install updates that no one other than Microsoft knows what they are actually for ? Well, they do have a site you can go to that describes the “fixes”. And then there are the times when the updates failed so you have to disable virus protection and repeat the process. And then you have to remember to re-enable virus protection. Windows Update is always there waiting for you to restart your system - and you will because inevitably your system will slow down for unknown reasons and of course the recourse is always to reboot. But Windows Update is ALWAYS watching: 1.5.3 Is Linux Really Better ? Bioinformatics thrives on open source tools the vast majority of which are built on Linux/UNIX. However, frameworks like R and Python will run on Windows so you CAN in fact do some things on Windows assuming you have control of your computer to install things. Linux offers an excellent package management system to help install specific tools (compilers and databases) you might need to develop code. It all depends on what you want to do. Most people who use Linux do not also run general office productivity apps on the same system although you could certainly do this. The typical Linux user is a scientist or developer who uses open source tools as part of their daily work. Let’s say that you read a research paper and see that there is a cool package or tool that was developed using open source so you want to run it. If you are lucky then it’s in the form a package that can be run under, for example, R in which case you can implement it on your Windows or Apple system. The problems come in when you want to “Scale Up” your activities and run tens, hundreds, or thousands of jobs at which point Linux is required. If you think that your computational activities will remain at a modest level then maybe you don’t need to learn or use Linux but in the era of “Big Data” that is something of a gamble. Amazon and Google both provide pre-made Linux images that come pre-installed with a number of tools likely to be of interest to a statistician or bioinformatics person. But you will still need to learn something about Linux administration be productive. However, a little knowledge will go a very long way 1.5.4 Cool Things About Linux See https://www.gotothings.com/unix/unix-features-and-advantages.htm for a long list some of which are summarized here: Portability: The system is written in high-level language making it easier to read, understand, change and, therefore move to other machines. The code can be changed and complied on a new machine. Customers can then choose from a wide variety of hardware vendors without being locked in with a particular vendor. Machine-independence: The System hides the machine architecture from the user, making it easier to write applications that can run on micros, mins and mainframes. Multi-Tasking: Unix is a powerful multi-tasking operating system; it means when a active task in in process, there can be a simultaneous background process working too. Unix handles these active and background threads efficiently and manages the system resources in a fair-share manner. Multi-User Operations: UNIX is a multi-user system designed to support a group of users simultaneously. The system allows for the sharing of processing power and peripheral resources, white at the same time providing excellent security features. Hierarchical File System: UNIX uses a hierarchical file structure to store information. This structure has the maximum flexibility in grouping information in a way that reflects its natural state. It allows for easy maintenance and efficient implementation. UNIX shell: UNIX has a simple user interface called the shell that has the power to provide the services that the user wants. It protects the user from having to know the intricate hardware details. 1.5.5 Linux is The Native Environment for Development. Linux provides support for almost any programming language you can think of. This includes Python, C/C++, Java, Perl, Ruby, FORTRAN, R, and many, many more. There are compilers and toolkits for using these languages on Windows assuming you can get the permission to install them and you know how to work the “Command Shell” in Windows. There are also IDEs (such as R Studio) that will run on Windows to insulate you from the command line but if you want to work on the domain of “Big Data” you will inevitably need to use the command line. Ironically, Microsoft, as a company, got its start by providing compilers for developing software products. They strayed from that mission (much to their financial advantage) to become the premier consumer operating system. Clearly this move worked out quite well for Bill Gates but the company took a direction guided by the needs of the mass market. Can’t say that I blame him for that. Anyway, bask in the glory of the splash screen for Microsoft Quick Basic which at one time was really cool if only for a short time. By then 1985 there were other compilers for “better” languages such as Pascal and C. 1.5.6 Command Line Knowledge is Next Level Stuff Linux offers the “Terminal Window” which is the primary interface to the operating system although Linux also provides a number of “nice” GUIs (Graphical User Interfaces) to interact with your files. Using the command line though becomes a very powerful way to create code and run it. Things like R Studio insulate you from having to do this but even that provides a way to interact with the “command line”. Windows command line support is terrible. In fact, Windows was designed to keep the end user AWAY from the command line which is massively inconvenient for those with a programming background or a general need to be productive with code. They do have something called “Powershell” which is aimed at Windows administrators but the end user can access it also. Note that if anyone ever asks you to do something to “edit the Windows Registry” then watch out ! 1.5.7 Is There Hope For Windows Users ? You can in fact get work done using Windows especially if you are using apps like R Studio, SAS, etc though at some point you will probably hit a permissions error or need to install something (e.g. LaTex) that requires a lot of work and troubleshooting just to do something that would take like 5 seconds on Linux or Apple OSX. Also remember that being able to scale up your analysis is more easily accomplished on Linux than Windows. This doesn’t mean that you should abandon your Windows laptop just that as you plan for a future career in research that might involve computation then you want to look at solutions that involve Linux. Both Google and Amazon offer excellent support for Linux instances as part of their cloud offerings. Even the Microsfot Azure cloud service offers Linux support as part of their service so they understand the importance of Linux in the scheme of things. 1.6 Is There a Middle Ground ? Yes there is. You can always use Windows to remotely access a Linux computer using tools such as Putty but this assumes that someone has setup that remote system for you. This is where Amazon and Google come in with their cloud services. In effect you are using your Windows laptop to access another computer so you don’t have to install very much on your local system. But this also assumes that you know something about Linux. 1.6.1 Virtualized Systems You can also use Virtualization software such as Oracle’s freely available Virtual Box that allows you to install Linux within a “fully virtualized computer” that is hosted within an application running on your Windows box. Just installing Virtual Box isn’t enough. You then have to pick the appropriate distribution of Linux you want to run and then install that. The advantage of this approach is that it provides access to a completely different operating system (in this case Linux) that appears to be an entire functioning machine that uses your system’s CD/DV, mouse, track pad, etc just like a “real” machine. You need to use key combinations to switch between your virtualized and host systems but that’s just part of the learning curve. VirtualBox runs on top of Apple, Windows, and Linux systems which means, for example, that you could run a copy of Windows on top of an Apple laptop. Using VirtualBox and fully exploring it’s power requires you to know about administration and management of the operating system in question which is why some people shy away from it though it remains a powerful tool for running multiple operating systems on one host. From a practical point of view you need to make sure that you desktop or laptop has enough memory and disk space to practically use VirtualBox since any operating systems you virtualize will share resources with your hardware. If you have around 8GB or more of RAM and at least 100GB free then you should be fine. But you also need to take into account any data sets you plan to process. 1.6.2 Dockers If using Virtualbox seems too much then consider using “Docker” technology which is a form of lightweight virtualization designed to give users easy access to specific services (e.g. other operating systems, analysis packages, databases,etc) without requiring a full on installation of something like VMWare or Virtualbox. Docker “images” are created by a community of interested users who then publish the images onto a repository or registry, usually Dockerhub, for use by others. Running them involves first installing the Docker software for your operating system and then issuing some commands that pulls down the image and executes it within a “container” that can interact with your local operating system. As an example, let’s consider the following scenario: I have R installed on my laptop and it has all the packages I need to do my work. I read some research paper that points me to a new R package that requires the latest version of R I have no interest in updating my local version of R just to get this package which might not ever do what I want it to do. What are my choices here ? Well, I could loin to a system somewhere that does have the latest version of R. This is where services like Amazon and Google come in handy since I can spin up my own Linux servers and experiment on them but let’s say I don’t want to spend any money on that. I could install Virtualbox and Linux on top of that but that’s too much work. I know, I’ll install the Docker software appropriate to my system (Apple) and run the latest version of R in a container. This executes the latest version of R in a protected container that in no way interferes with my existing version of R. I could also do this with another operating system altogether such as running Ubuntu Linux in a container on my Apple. Steves-MacBook-Pro:~ esteban$ docker run -it rocker/r-base Unable to find image &#39;rocker/r-base:latest&#39; locally latest: Pulling from rocker/r-base 71c170c5dae2: Pull complete 1b76173b98c5: Pull complete 1b00be862536: Pull complete c48ed365264c: Pull complete b2f3e26a95d6: Pull complete bdb9fc7fc7fb: Pull complete Digest: sha256:0589141389482d3211dbc9ccef20e1b426cc8ed7644c2ef0f60862becf3bea4e Status: Downloaded newer image for rocker/r-base:latest R version 3.5.3 (2019-03-11) -- &quot;Great Truth&quot; Copyright (C) 2019 The R Foundation for Statistical Computing Platform: x86_64-pc-linux-gnu (64-bit) R is free software and comes with ABSOLUTELY NO WARRANTY. You are welcome to redistribute it under certain conditions. Type &#39;license()&#39; or &#39;licence()&#39; for distribution details. Natural language support but running in an English locale R is a collaborative project with many contributors. Type &#39;contributors()&#39; for more information and &#39;citation()&#39; on how to cite R or R packages in publications. Type &#39;demo()&#39; for some demos, &#39;help()&#39; for on-line help, or &#39;help.start()&#39; for an HTML browser interface to help. Type &#39;q()&#39; to quit R. &gt; 1.6.3 Anaconda From the Anaconda page: Conda is an open source package management system and environment management system that runs on Windows, macOS and Linux. Conda quickly installs, runs and updates packages and their dependencies. Conda easily creates, saves, loads and switches between environments on your local computer. It was created for Python programs, but it can package and distribute software for any language. Conda is tool that allows you to manage Python and (to an extent) R installations. It insulates you from the details of installing Python versions and allows you to maintain multiple versions of Python on one system should you need that type of environment. An advantage of this is that you can then easily install something like Jupyter Notebooks that facilitate development of Python code. 1.7 Apple OSX / macOS ? Hmm. Isn’t Apple a proprietary system ? Why yes it is but Apple laptops, unbeknownst to most people, runs a form of UNIX natively ! It’s been there for some time. Just find the “Terminal” application. Start it up and you will see something like the following. The interesting thing about this is that the GUI (The Graphical User Interface) that you interact with is itself a process that runs on top of UNIX ! The reason I am advocating Apple is not because I’m fond of paying more for a computer (see comparison below) but because it’s much close to Linux by far than MS Windows which is good news for anyone who does BioMedical or Bioinformatics work - more generally anything opensource. 1.7.1 The Dark Years of Apple It’s way outside of the scope of this discussion to explain the history of Apple products and it’s various operating system but for a number of years (mostly up to an including 2001) it suffered from stability and performance issues due to its general inability to effectively manage multiple processes which would then lead to unexpected crashes and screens like the following. This was so common that people called it The Bomb. The Microsoft equivalent was called “The Blue Screen of Death” aka BSOD. And there was a time when both Apple and Microsoft battled it out for the crown of unexpected crashes. Modern Apple systems do not crash nearly as often as the systems of old but occasionally they can, (due usually to hardware issues), and when it happens, one usually observes what is known as The Spinning Beach ball or The Beach ball of Death. In reality this can be more easily addressed than The Bomb which was more strongly associated with Max OS 9 but it’s still a pain. Take comfort in the knowledge that it happens far less frequently than a decade ago. This is due to the fact that the Apple Operating System is running on top of UNIX which handles processes very efficiently. 1.7.2 Apple OSX vs Previous Apple Operating Systems Around 2001 Apple decided to base it’s interface on a UNIX type of operating system. This is something of a simplification but this introduced enhanced stability for the platform which in turn made development for OSX more uniform than before. What this means for you is that you have access to UNIX. This does not mean that you will instantly know how to use it but it’s there if you want it. Check out this graphic which presents the history of the UNIX operating system and Apple’s relation to that development tree: Don’t get me wrong - simply running UNIX does not guarantee enhanced performance for applications that don’t take advantage of it but the Apple OSX User interface is very well integrated with UNIX which provides, at least in my experience, a much smoother experience overall with fewer crashes. 1.7.3 Let’s Go Shopping ! Of course I understand the appeal of Windows-based laptops and desktops - they are quite inexpensive when compared to Apple products. For example check out the price on this Dell Inspiron. It also includes a 15.6 inch screen, a camera, fingerprint reader, touch pad, DVD, a 512GB Solid State Drive, and a bunch of USB and HDMI ports. When looking at the comparable Apple there is a drastic price difference though keep in mind that the CPU is very good as is the display. But still there is a financial consideration to be made. But consider that the hardware and software are designed and implemented by the same company whereas with Windows based laptops the hardware can be designed by any number of vendors. For me, the performance and the relatively headache-free experience of not having viruses is worth it. Especially since I can develop very easily. Where this all falls apart is that with Window-based hardware one can usually add storage much cheaper. There are a number of ways to manage the installation of UNIX tools on your Apple laptop (or desktop) but many of the tools you would want access to at the command line are already installed. Apple offers something called XCode which provides access to compilers for development. Obviously they would like for you to develop applications that run natively on OSX but this isn’t at all a requirements. But since it’s all UNIX under the hood you can have compilers like gcc and gfortan. 1.7.4 Managing Software Locally Usually you want to install one or more programming environments to facilitate analysis and the possible development of packages for eventual sharing with others. So it’s common to install things like RStudio and perhaps Python along with commercial tools like SAS and MATLAB. This is possible and if done with care you should be okay. Specifically make sure you have plenty of hard drive space and plenty of RAM (at least 8GB or more) to realistically do any work. 1.7.5 RStudio This is usually a very straightforward installation process with few surprises and for the most part RStudio works very well. Where it doesn’t work well is when you need to install packages that in turn require some other version of R than the one you have installed. 1.7.5.1 BioConductor BioConductor is an add on environment for R that is dedicated to managing and analyzing data types of interest to bio medical investigators. However, it brings its own set of problems in that you have to use a special installer that is independent of the typical R package installer. This is because BioConductor imposes a specific structure on top of the data to ensure that downstream BioConductor packages can easily “digest” the incoming data. BioConductor is also highly dynamic and packages are updated frequently which can lead to version collisions. In recognition of some of these problems the BioConductor team recently introduced a new tool to manage BioConductor installations that allows one to install multiple versions of BioConductor alongside each other with interference. This is a convenience worth having if you plan to do a lot of bioinformatics work. To install BioConductor do the following within an active R installation: # Get the installer if you don&#39;t already have it install.packages(&quot;BiocManager&quot;) # This will install most of the basic packages BiocManager::install() # Find available Bioconductor packages BiocManager::available() 1.7.5.2 Python Python comes by default on Apple systems. The newer systems come with Python version 3 as general support for Python 2 is going away. This has nothing to do with Apple. It’s a Python community kind of thing. So the bottom line is that if you need to have Python access you have it by default BUT it’s best not to mess with the default installation since Apple OSX relies on Python to do some things administratively. At least this is what I have found. What I generally do is use the Conda installer to manage different versions of Python on my Apple. You can also do this on Linux or MS Windows ! There is a smaller version of Conda called Miniconda which has a smaller installation foot print so you could start with that. That’s the only difference. Both of these allow you to install multiple versions of Python in a way that insulates those respective versions from each other. This is great for evaluating, testing, and running various Python modules that might require differing versions of Python. Conda provides access to a number of pre-built channels that contain pre-built modules (such as numpy, scipy, scikit, matplotlib) which means all you have to do is install them without concern for downloading and compiling them yourself. This is a true convenience in that you almost never have to deal with version conflicts or compile modules yourself. Steves-MacBook-Pro $ conda env list # conda environments: # base * /Users/esteban/anaconda3 "],
["virtualization.html", "Chapter 2 Virtualization 2.1 Virtual Box 2.2 Using Virtualization Farms 2.3 Running RStudio on Amazon 2.4 Accessing Your Instance 2.5 Getting Data Into Your Instance 2.6 Accessing S3 from EC2 Instances 2.7 Shiny Server", " Chapter 2 Virtualization Virtualization can help deal with the problem of having to use multiple operating systems although it requires some level of operating system administration knowledge to fully exploit. At the most basic level a person can install a Virtualization package onto a desktop or laptop and then host one or more “guest” operating systems on top of that which will appear to be running “natively” on your hardware. The “guest” opersting system will use the hard drive, memory, keyboard, mouse, touch pad just as it was running on its own. OF coruse a limistation of this approach is that the guest operating system will be competing with your host operasting system for resources so you will need to appropriately allocate resources to the guest OS when you set it up to ensure decent performance. The most common virtualization setup I see are people with Apple laptops wanting to run MS Windows on their Apple. Apple even has a product for this called Parallels which cost around $80 though open soruce tools like Virtualobox can also provide accress There is a also a product called VMWare which can do this so there are some options. Of course there are Windows users who want to run Linux on top of their Windows OS. You could also be a Windows user who wants to run a protected copy of Windows on top of your “host” Windows to do some experiments without impacting your natively installed copy. 2.1 Virtual Box There is a free virtualization tool called VirtualBox that can be downloaded for free for use on Windows, Apple, or Linux hardware. It works pretty well and the price is right. Keep in mind that any operating systems you install within Virtual Box will share the hard drive and memory of you desktop or laptop. Also consider that if you wanted to run MS Windows as a guest operating system that you would need to get a license for it. That is, just because you have the ability to run Windows as a guest OS does not mean that it would be free. You are still bound by the license terms that apply to any version of Windows. With Linux of course it’s free. Here is a screenshot of my Apple laptop where I used a copy of Virtualbox to host an installation of Mint Linux which is a small version of Linux. 2.2 Using Virtualization Farms You have probably heard of Amazon. It provides virtualization capabilities at a very large scale as well as many other services that exploit this ability. Both Google and Microsoft also have this capability but Amazon has a head start. 2.3 Running RStudio on Amazon I’ll assume that you know something about getting into Amazon so I’ll jump right in. For this example I will use the Ubuntu 18 which is the newest although typically one would use a version that has been around for a few years. For Ubuntu that would be version 16 or even 14. The advantage of using something older is that there is more Google information on various problems that might emerge. I’m picking Ubuntu 18 because I wanted to see how it differed, if at all, from the previous versions. There are some oddities but nothing major. 2.3.1 Why Ubuntu ? I’m using Ubuntu because it is the most friendly Linux OS for bioinformatics tools although almost any known version of Linux could be used - it’s just that you might have to use different package managers. CentOS is a popular alternative and there are a number of other “distros”. 2.3.2 Start An Instance Login to your Amazon AWS account and select something like a t2.medium instance with around 50-100GB of space. This will vary with your project needs but this is just an example. 2.3.3 Add Some Storage Add some storage to the instance. If you find yourself wanting to add a lot of storage here then you should consider adding a separate volume. That way when we later create an AMI (Amazon Machine Image) you don’t make an image out of a very large volume which will in turn cost more money. 2.3.4 Get A Key As always you will need a key to get into your instance. Either select an existing key or create a new one. 2.3.5 Installing R Once you have your instance up and running let’s install the latest version of R. Strictly speaking we don’t have to install the absolute latest version. If we make no effort to get the latest version then we will get whatever version of R was current at the time the release was built. You can refer to this page for specific information on how to get the latest R release. With Linux there are a number of supporting packages that you will need to get to install packages like tidyverse. The same is true with the RStudio Server software. $ sudo apt install apt-transport-https software-properties-common $ sudo apt install build-essential $ sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys E298A3A825C0D65DFD57CBB651716619E084DAB9 $ sudo add-apt-repository &#39;deb https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/&#39; $ sudo apt install libcurl4-openssl-dev libssl-dev libxml2-dev $ sudo apt update $ sudo apt install r-base So for now just accept that you will have to install some packages in support of getting the latest version of R. Knowing something about system administration is a good thing particularly as it relates to the package manager “apt-get”. You don’t have to be an expert but it’s important to know how to add, remove, and update packages. $ R --version R version 3.5.3 (2019-03-11) -- &quot;Great Truth&quot; Copyright (C) 2019 The R Foundation for Statistical Computing Platform: x86_64-pc-linux-gnu (64-bit) R is free software and comes with ABSOLUTELY NO WARRANTY. You are welcome to redistribute it under the terms of the GNU General Public License versions 2 or 3. For more information about these matters see http://www.gnu.org/licenses/. # Here you can install tidyverse. This will compile the code for tidyverse $ R &gt; install.packages(&quot;tidyverse&quot;) 2.3.6 Installing RStudio Server The next step involves installing the RStudio server software which requires some supporting files: $ sudo apt-get -y install gdebi-core Next we want to go to the Downloads page for RStudio to get a version of RStudio server that is approved for use with Ubuntu 18. $ wget https://download2.rstudio.org/rstudio-server-1.1.463-amd64.deb $ sudo gdebi rstudio-server-1.1.463-amd64.deb Created symlink /etc/systemd/system/multi-user.target.wants/rstudio-server.service → /etc/systemd/system/rstudio-server.service. ● rstudio-server.service - RStudio Server Loaded: loaded (/etc/systemd/system/rstudio-server.service; enabled; vendor preset: enabled) Active: active (running) since Tue 2019-04-02 02:33:57 UTC; 1s ago Process: 32618 ExecStart=/usr/lib/rstudio-server/bin/rserver (code=exited, status=0/SUCCESS) Main PID: 32628 (rserver) Tasks: 3 (limit: 4704) CGroup: /system.slice/rstudio-server.service └─32628 /usr/lib/rstudio-server/bin/rserver Apr 02 02:33:57 ip-172-30-1-144 systemd[1]: Starting RStudio Server... Apr 02 02:33:57 ip-172-30-1-144 systemd[1]: Started RStudio Server. $ sudo rstudio-server verify-installation 2.4 Accessing Your Instance If the installation went as expected then fire up your favorite web browser and point it at the public IP number associated with your instance: http://18.212.63.117:8787 This probably won’t work unless as part of the instance setup you thought to allow inbound connections on port 8787. Most people forget but that’s okay. You can go back and fix this by looking at your instance details and identifying your security group. After that you can change the inbound rules. Now you should be able to access the web interface for RStudio with your browser. The question then becomes what userid should you use ? Well you could add one or more userids and create passwords. The installation of RStudio is able to accept userid and password information for users on your system. Let’s change the password on the default ubuntu password so we can get in. To do this go back to your terminal where you logged into your instance. Use the passwd command to change the password. Afer you do this then you can log into your RStudio instance $ sudo passwd ubuntu Enter new UNIX password: Retype new UNIX password: passwd: password updated successfully 2.5 Getting Data Into Your Instance You now have access to a remote instance of RStudio but you need to figure out how to get data into it. You could use something like the scp or sftp command to upload data from your laptop into your instance. That’s one way to do this. Let’s say we have a local folder named test_data that we want to copy up to our instance. $ scp -i ~/.ssh/bios560.pem -r test_data ubuntu@18.212.63.117:/home/ubuntu bird 100% 13 0.5KB/s 00:00 cat 100% 0 0.0KB/s 00:00 dog 100% 15 0.6KB/s 00:00 2.6 Accessing S3 from EC2 Instances Another way to get data into your instance is by copying it over from your S3 buckets. S3 is object based storage that is very cheap and you can stock pile data over there until you are ready to analyze it. But you need to know how to copy it over. There are a couple of ways to do this. The first is that you could assign a role that would allow your instance to access S3 as you create the instance. Or you could make a change once it is up and running as follows: The idea is to assign a role that will allow your EC2 instance to “read” your S3 buckets. So you can now access your S3 resources using the AWS CLI (Command Line Interface). You can do this from your Terminal window. For the S3 CLI documentation go here $ sudo apt-get install awscli $ aws s3 ls 2012-11-04 02:23:18 R_Stuff 2014-04-24 18:53:17 bimcore_final_figures 2015-04-08 18:29:09 cm-89cc48c8931698be927013c2775cf11e 2018-11-30 03:31:29 juniferous 2014-11-03 21:44:19 pittaraujo13 2014-04-24 18:39:45 steviep42bitbucket $ aws s3 ls s3://juniferous PRE AWSLogs/ 2018-12-05 20:19:04 97 error.html 2018-12-04 21:57:39 13 healthcheck.html 2018-12-05 20:19:03 732 index.html 2019-04-01 21:37:18 63566904 rstudio-server-1.1.463-amd64.deb 2.7 Shiny Server You can install Shiny Server also using the directions found here. Login to your instance you created previously. The following command will result in lots of messages. It installs the shiny server along with the pre requisites. You might encounter some warning messages. $ sudo su - \\ -c &quot;R -e \\&quot;install.packages(&#39;shiny&#39;, repos=&#39;https://cran.rstudio.com/&#39;)\\&quot;&quot; So now download the actual server code and install it. You should not encounter any errors when doing this. The last thing you should see is a message indicated that the server has started. By default, your server will be running on port 3838 so make sure your instance firewall / security group will allow access on that port. $ sudo apt-get install gdebi-core $ wget https://download3.rstudio.org/ubuntu-14.04/x86_64/shiny-server-1.5.9.923-amd64.deb $ sudo gdebi shiny-server-1.5.9.923-amd64.deb So the default location for the server apps are in /srv/shiny-server/sample-apps So point your browser at whatever your IP number is followed by /sample-apps/rmd As an example **http://3.87.30.168:3838/sample-apps/rmd/** $ ls -lR .: total 8 drwxrwxr-x 2 root root 4096 Apr 3 15:42 hello drwxrwxr-x 2 root root 4096 Apr 3 15:42 rmd ./hello: total 8 -rw-rw-r-- 1 root root 642 Sep 11 2018 server.R -rw-rw-r-- 1 root root 494 Sep 11 2018 ui.R ./rmd: total 4 -rwxrwxr-x 1 root root 484 Sep 11 2018 index.Rmd "],
["dockers-1.html", "Chapter 3 Dockers 3.1 Scenarios 3.2 Differences From VMs 3.3 Docker Terminology 3.4 RShiny", " Chapter 3 Dockers If using Virtualbox seems too much then consider using “Docker” technology which is a form of lightweight virtualization designed to give users easy access to specific services (e.g. other operating systems, analysis packages, databases,etc) without requiring a full on installation of something like VMWare or Virtualbox. Docker “images” are created by a community of interested users who then publish these images onto a repository or registry, usually Dockerhub, for use by others. Running them involves first installing the Docker software for your operating system and then issuing some commands that pulls down the image and executes it within a “container” that can interact with your local operating system. 3.1 Scenarios As an example, let’s consider the following scenarios: I’m on a Windows or an Apple laptop and I need an Ubuntu OS to run some software I read about that will only run on Linux. I don’t want to install Virtualbox I have R installed on my laptop and it has all the packages I need to do my work. I read some research paper that points me to a new R package that woild require me to update my version of R but I really don’t want to do this. I am developing an R (or Python) package and I want to share it with my colleagues without requiring them to do install a lot of pre-requisites. I am developing software that has a web server, database, and a front end user facing application. I want to develop this all locally without having to involve system administrators and other people. Docker solves these problems. It’s not the only solution but it is becoming incresasingly popular to develop and design applications to run inside of light weight “containers” that sit on top of you OS without interfering with it. Let’s look at scenario number one again: I’m on a Windows or an Apple laptop and I need an Ubuntu OS to run some software I read about that will only run on Linux. I don’t want to install Virtualbox Here is the Docker solution. This is using my Apple laptop. $ docker run -it ubuntu Unable to find image &#39;ubuntu:latest&#39; locally latest: Pulling from library/ubuntu 898c46f3b1a1: Pull complete 63366dfa0a50: Pull complete 041d4cd74a92: Pull complete 6e1bee0f8701: Pull complete Digest: sha256:017eef0b616011647b269b5c65826e2e2ebddbe5d1f8c1e56b3599fb14fabec8 Status: Downloaded newer image for ubuntu:latest root@85455cbcf54d:/# ls bin boot dev etc home lib lib64 media mnt opt proc root run sbin srv sys tmp usr var root@85455cbcf54d:/# uname -a Linux 85455cbcf54d 4.9.125-linuxkit #1 SMP Fri Sep 7 08:20:28 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux root@85455cbcf54d:/# I have R installed on my laptop and it has all the packages I need to do my work. I read some research paper that points me to a new R package that woild require me to update my version of R but I really don’t want to do this. Steves-MacBook-Pro:~ esteban$ docker run -it rocker/r-base Unable to find image &#39;rocker/r-base:latest&#39; locally latest: Pulling from rocker/r-base 71c170c5dae2: Pull complete 1b76173b98c5: Pull complete 1b00be862536: Pull complete c48ed365264c: Pull complete b2f3e26a95d6: Pull complete bdb9fc7fc7fb: Pull complete Digest: sha256:0589141389482d3211dbc9ccef20e1b426cc8ed7644c2ef0f60862becf3bea4e Status: Downloaded newer image for rocker/r-base:latest R version 3.5.3 (2019-03-11) -- &quot;Great Truth&quot; Copyright (C) 2019 The R Foundation for Statistical Computing Platform: x86_64-pc-linux-gnu (64-bit) R is free software and comes with ABSOLUTELY NO WARRANTY. You are welcome to redistribute it under certain conditions. Type &#39;license()&#39; or &#39;licence()&#39; for distribution details. Natural language support but running in an English locale R is a collaborative project with many contributors. Type &#39;contributors()&#39; for more information and &#39;citation()&#39; on how to cite R or R packages in publications. Type &#39;demo()&#39; for some demos, &#39;help()&#39; for on-line help, or &#39;help.start()&#39; for an HTML browser interface to help. Type &#39;q()&#39; to quit R. &gt; Dockers are far more light weight than VMs. Think of it this way: If you have 30 Docker containers that you want to run, you can run them all on a single virtual machine (or real machine). To run 30 virtual machines, you’ve got to boot 30 operating systems with at least minimum resource requirements available before factoring the hypervisor for them to run on with the base OS. https://blog.codeship.com/why-docker/ Containers work a little like VMs, but in a far more specific and granular way. They isolate a single application and its dependencies—all of the external software libraries the app requires to run—both from the underlying operating system and from other containers. https://www.infoworld.com/article/3310941/why-you-should-use-docker-and-containers.html 3.2 Differences From VMs Here is a diagram of what a Virtual Server might look like. Notice that there is a “Hypervisor” on top of the host that enables you to install and maintain multiple operating systems. See this link from which the following graphics were taken for more discussion for more discussion And here is the diagram for a container / Docker approach: Lastly, we have a diagram of the Docker Universe. What this means to you is that you will install the Docker software for your computer which then executes a daemon (a persistent process) that can communicate with Docker Hub to identify and obtain existing images that you can run locally. You can develop images and then push them up to Docker Hub (as you would with GitHub for general source code) for others to use. 3.3 Docker Terminology The terminology is pretty easy and straightforward. Docker hub is a free (for the most part) registry service to maintain Docker images thats can be pulled down to your computer. You can then run the images inside of containers. There are commands to develop your own images that can be executed in containers which can talk to each other where desired. Of course there are commands that allow you to find, execute, and maintain images and containers as well as develop them. Go to the Docker site and install the code for your platform. 3.3.1 Images You can pull an image. Once it’s been downloaded it will stay local unless you make and effort to remove it. Think of an image as read-only package that has whatever you need to do something. # Show current docker activity on your machine $ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES # Show all activity (past and present) $ docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 85455cbcf54d ubuntu &quot;/bin/bash&quot; About an hour ago Exited (0) 2 minutes ago keen_wright $ docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE ubuntu latest 94e814e2efa8 3 weeks ago 88.9MB You can search for images based on what they do. $ docker search python NAME DESCRIPTION STARS OFFICIAL AUTOMATED python Python is an interpreted, interactive, objec… 4026 [OK] django Django is a free web application framework, … 805 [OK] pypy PyPy is a fast, compliant alternative implem… 175 [OK] kaggle/python Docker image for Python scripts run on Kaggle 114 [OK] frolvlad/alpine-python3 The smallest Docker image with Python 3.5 (~… 96 [OK] Let’s look for a images that have the R tidyverse, Rstudio, and Shiny. There is a project called “rocker” that has almsot all the cool R stuff you would want in the form of a Docker image. $ docker search rocker | grep shiny rocker/shiny-verse Rocker Shiny image + Tidyverse R packages. U… $ docker search rstudio NAME DESCRIPTION STARS OFFICIAL AUTOMATED rocker/rstudio RStudio Server image 243 [OK] opencpu/rstudio OpenCPU stable release with rstudio-server (… 29 [OK] rocker/rstudio-stable Build RStudio based on a debian:stable (debi… 14 [OK] So someone went ahead and made images with all that you need to run these packages. When we run this we have to tell the image what password we want to provide for the rstudio password. The rm option tells docker to remove the image once we are done using the image. $ docker run --rm -e PASSWORD=&#39;steve&#39; -p 8787:8787 rocker/verse That’s great and all but how then does the Docker image interact with the local filesystem on your laptop ? First, let’s stop the running container docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 292adbfaa2e1 rocker/verse &quot;/init&quot; 3 hours ago Up 3 hours 0.0.0.0:8787-&gt;8787/tcp optimistic_cori $ docker stop optimistic_cori optimistic_cori I’m on an Apple so I want my home folder to be available on the Rstudio server under the directory as /home/esteban $ docker run --rm -v /Users/esteban:/home/esteban -e PASSWORD=&#39;steve&#39; \\ -p 8787:8787 rocker/verse 3.4 RShiny So let’s see within my home folder I have a folder with Server.R and UI.R files. This is a very simple application. Let’s look at the content of the files: $ cd appdir/ $ ls Server.R UI.R $ cat Server.R # Define server logic required to print &quot;Hello World&quot; when button is clicked shinyServer(function(input, output) { # Create action when actionButton is clicked observeEvent(input$Print_Hello,{ # Change text of Server_Hello output$Server_Hello = renderText(&quot;Hello world from server side&quot;) }) }) $ cat UI.R library(shiny) # Define UI for application print &quot;Hello world&quot; shinyUI( # Create bootstrap page fluidPage( # Paragraph &quot;Hello world&quot; p(&quot;Hello world&quot;), # Create button to print &quot;Hello world&quot; from server actionButton(inputId = &quot;Print_Hello&quot;, label = &quot;Print_Hello World&quot;), # Create position for server side text textOutput(&quot;Server_Hello&quot;) ) ) Now let’s run a Shiny Server $ docker run -p 3838:3838 -v /Users/esteban/appdir/:/srv/shiny-server/ rocker/shiny Nezt let’s lood the Shiny App "]
]
