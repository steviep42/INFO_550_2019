[
["twitter-social-media.html", "Chapter 5 Twitter - Social Media 5.1 Twitter Uses 5.2 Why Should You Care ? 5.3 Twitter Anatomy 5.4 Accessing From R - rtweet 5.5 Authenticating From R 5.6 Some Basic Tips 5.7 Looking for People Tweeting About COPD 5.8 Cleaning and Tidying 5.9 Make The Word Cloud 5.10 Bi-Grams", " Chapter 5 Twitter - Social Media 5.1 Twitter Uses Tweets come from many sources - people, politicians, media outlets, sports teams, movie stars, etc Multimedia content can be sent along with a Tweet (pics, movies, emojis) Real time communication Anyone can create an account and also sign up to use the API Proxy news service 5.2 Why Should You Care ? That’s really up to you and your personal interests but consider that tweets can be worth a lot of money. https://www.freevaluator.com/tools/twitter-username-worth https://www.tweetbinder.com/blog/economic-value-tweet/ 5.3 Twitter Anatomy User Name: A unique userid Time Stamp: When the tweet went out Text: The content of the tweet Hashtags: Words prefixed with a # character. Links: Hyper links to other web sources Replies: Replies to a posted tweet Retweets: When someone shares a third party tweet with followers Favorites: A history of tweets you have liked Latitude / Longitude: Some tweets have geo coding information 5.4 Accessing From R - rtweet The rtweet package is very cool but you have to do the following: Install the rtweet package Setup a Twitter account. It’s free at https://twitter.com/ Note that it requires your cell number to create an App (But you can delete the account after the class is over). After you have created your account then go http://apps.twitter.com From with your account create an ”application”so you can mine other tweets: Name: rtweet testing Description: Testing Account for rtweet Website: http://twitter.com/userid (replace userid with your userid) Callback URL: http://127.0.0.1:1410 Create App 5.5 Authenticating From R Now within R, You need to do the following. You only need to do it once per session to get authenticated to use Twitter from within R. # Running this code will contact Twitter and load a web page. # If authentication is successful then you will see a web page # with the contents of library(rtweet) twitter_token &lt;- create_token( app = &quot;rtweetpitt&quot;, consumer_key = &quot;HBNyMiXbPsdsdiiisdoodvIUBsBpRY8zH&quot;, consumer_secret = &quot;Tl6uTC4quNGONXsddLoRSIn9ULe7LReHPyYleUMUlM&quot;) # Create a Function to Pull in Some Tweets my_search_tweets &lt;- function(string=&quot;Katy Perry&quot;,n=500) { require(rtweet) tweet_table &lt;- search_tweets(string,n=n, retryonratelimit = TRUE, include_rts = FALSE, lang = &quot;en&quot;) return(plain_tweets(tweet_table$text)) } raw_tweets &lt;- my_search_tweets(&quot;Katy Perry&quot;) katy_raw_tweets &lt;- raw_tweets # save for later [1] &quot;i blame my bad eating habits on katy perry. idk why but i do.&quot; [2] &quot;When I was 10, I slept over at my friend&#39;s house and she made me watch the Katy Perry movie but little does she know, when she fell asleep, I changed it to a JFK conspiracy documentary&quot; But wait. How can these be worth $86,904 each ? Well these are tweets ABOUT Katy Perry. Let’s get some tweets that she herself actually issued and then see if they are worth that much. kpt &lt;- get_timeline(&quot;katyperry&quot;,n=100) &gt; plain_tweets(kpt$text)[1:9] [1] &quot;I don&#39;t know if anyone noticed but I almost broke down in tears having to pick one of my children #americanidol&quot; [2] &quot;Daydreaming of a world where we have 14 #americanidol(s) (cause this SKRESSFUL)//t.co/o3u4eYRt4d&quot; [3] &quot;Is anyone else stress snacking during the commercial breaks? #americanidol&quot; [4] &quot;From 15 years of being a coachella festival goer to guesting with @zedd on his main stage set not gonna lie feels pretty chill. Thanks area for the shine by @ronyalwin @ you&#39;re doing great//t.co/gwU12MpAla&quot; [5] &quot;we must protect wherearetheavocados, beings like her don&#39;t enter our orbit often @ Coachella, California//t.co/078jLTZQXy&quot; [6] &quot;You think your favs are safe, think again. @AmericanIdol//t.co/xF53nLvGwj&quot; [8] &quot;It&#39;s time for y&#39;all to pull out your hair over these contestants #JesusTakeTheWheel #AmericanIdol//t.co/1vxNkFTaYp&quot; [9] &quot;After you&#39;re done watching Idol, East Coast (and before yours begins, West Coast), you might want to check out the Coachella live stream... around 7:30pm poss? //t.co/tXVz4J1Ra4 - Channel 1 #GetYouAGirlWhoCanDoBoth&quot; 5.6 Some Basic Tips The rtweet package is a well written and very full featured package that does a lot for you so you don’t have to. However, you do need to become familiar with the various options to get usable text. For example maybe you don’t want retweets in the tweets or user handles. You might also want tweets from a specific location or in a specific language. # Get tweets in French nd &lt;- search_tweets(&quot;#notredame&quot;,include_rts=FALSE,lang=&quot;fr&quot;) plain_text(nd$text)[95:100] &gt; plain_tweets(nd$text)[95:99] [1] &quot;#LCI le propagandiste d&#39;extrme droite Andre Bercoff raconte n&#39;importe quoi en prtendant qu&#39;il y a eu des milliers de tweets se flicitant de l&#39;incendie de #notredame c&#39;est parfaitement faux #24hpujadas//t.co/vgU8mGutCV&quot; [2] &quot;Le Prsident de la Rpublique @EmmanuelMacron s&#39;adressera la Nation ce soir, 20h. #NotreDame #NotreDameCathedralFire #Notre_Dame_de_Paris #Macron20h#Macron//t.co/GwxoUt5lsj&quot; [3] &quot;Zineb chie.... Volume 20 opus 34.... A dguster au fond des chiottes.... #NotreDame//t.co/PUmIJtrsYl&quot; [4] &quot;\\&quot;#NotreDame a tenu. Ses votes millnaires sont restes debout. Certes, Notre-Dame est abme, mutile, mais elle continuera de vivre. Ds lors que les piliers tiennent et portent l&#39;difice, il est toujours possible de reconstruire.\\&quot; #NotreDameDeParis//t.co/6YYo3QtGhU&quot; [5] &quot;Jamais un monument n&#39;avait autant touch le cur de l&#39;humanit #NotreDame #SauverNotreDame&quot; # English &gt; nd &lt;- search_tweets(&quot;#notredame&quot;,include_rts=FALSE,lang=&quot;en&quot;) Searching for tweets... Finished collecting tweets! &gt; plain_tweets(nd$text)[95:100] [1] &quot;Gut wrenching but still hauntingly beautiful. Amazing work by the Paris fire teams to preserve so much of the glasswork. #notredame//t.co/smoZaLqXwG&quot; [2] &quot;Ancient Notre Dame artifact found preserved #NotreDame//t.co/V8lZ8lE9zW&quot; [3] &quot;@joshscampbell There you go again criticizing Mr. Trump. Clearly, more raking could have saved the roof, an inspired idea. @POTUS @realDonaldTrump @NotreDame #NotreDame @PressSec @VP&quot; [4] &quot;To all the people thinking #notredame should not be rebuilt and the money given to the poor because that&#39;s what Jesus would want. You are wrong. No where in the Bible does Jesus say don&#39;t make/do beautiful costly things for me. In fact the opposite, Jesus went to the temple....&quot; [5] &quot;I keep singing &#39;The Bells of Notre Dame&#39; from the Disney movie... I know it&#39;s inappropriate but, damn, the place and that film are so iconic. The place stands for humanity and it must be fully restored. #NotreDame&quot; [6] &quot;Lot of empathetic discussion on Twitter by Mexicans about yesterday&#39;s conflagration at #NotreDame in Paris. \\&quot;How would we feel if #ChichenItza were destroyed,\\&quot; is a common refrain. Chichen Itza WAS destroyed and left to ruin; Consolidation and/or restoration began only in 1923.//t.co/6d9EhAvXz4&quot; 5.7 Looking for People Tweeting About COPD Let’s look at something more serious: raw_tweets &lt;- my_search_tweets(&quot;COPD&quot;) raw_tweets [995] &quot;Rebecca lives with COPD and is being treated for non-tuberculous mycobacterial infection (NTM) as well. She&#39;s looking forward to being clear of the NTM infection after 18 months&#39; treatment. //t.co/Vo7L5Fdco1&quot; [996] &quot;Do you have COPD? Are you receiving the care that you&#39;re entitled to? Complete your online COPD patient passport to find out now. Discover if you&#39;re getting the care that you are eligible for, and what to talk to your doctor about if not //t.co/9Jyonn2PeG//t.co/js88XSHF0E&quot; [997] &quot;Is #COPD associated with alterations in #hearing? A systematic review meta-analysis://t.co/jnXA6boq0N//t.co/KYfOxgL4aF&quot; [998] &quot;omg this is like when im teaching COPD clients breathing exercises in hospital but now i have to use it on myself CALM DOWN MY HEART #PERSONAWelcomeParty&quot; [999] &quot;#mdpidiagnostics Predicting #Pulmonary Function Testing from Quantified Computed #Tomography Using Machine Learning Algorithms in Patients with #COPD @UniHeidelberg @UBMannheim @dzhk_germany //t.co/FppyxJ5J5F//t.co/PspkxCLdKj&quot; [1000] &quot;@KTHopkins Hidden disabilities such as COPD, MS, Crohn&#39;s disease and arthritis can affect things like pain, stamina, breathing, and other things that influence how far someone can walk. When you are old or unwell, it will be you in a wheelchair someday. Pray that people are kind, instead.&quot; So you might want to look at the data structure that is returned because it can give a lot of information for your research. copd_tweets &lt;- search_tweets(&quot;#COPD&quot;) # Here are all the variables associated with each tweet # There are 88 columns worth of information ! names(copd_tweets) [1] &quot;user_id&quot; &quot;status_id&quot; [3] &quot;created_at&quot; &quot;screen_name&quot; [5] &quot;text&quot; &quot;source&quot; [7] &quot;display_text_width&quot; &quot;reply_to_status_id&quot; [9] &quot;reply_to_user_id&quot; &quot;reply_to_screen_name&quot; [11] &quot;is_quote&quot; &quot;is_retweet&quot; [13] &quot;favorite_count&quot; &quot;retweet_count&quot; [15] &quot;hashtags&quot; &quot;symbols&quot; [17] &quot;urls_url&quot; &quot;urls_t.co&quot; [19] &quot;urls_expanded_url&quot; &quot;media_url&quot; [21] &quot;media_t.co&quot; &quot;media_expanded_url&quot; [23] &quot;media_type&quot; &quot;ext_media_url&quot; [25] &quot;ext_media_t.co&quot; &quot;ext_media_expanded_url&quot; [27] &quot;ext_media_type&quot; &quot;mentions_user_id&quot; [29] &quot;mentions_screen_name&quot; &quot;lang&quot; [31] &quot;quoted_status_id&quot; &quot;quoted_text&quot; [33] &quot;quoted_created_at&quot; &quot;quoted_source&quot; [35] &quot;quoted_favorite_count&quot; &quot;quoted_retweet_count&quot; [37] &quot;quoted_user_id&quot; &quot;quoted_screen_name&quot; [39] &quot;quoted_name&quot; &quot;quoted_followers_count&quot; [41] &quot;quoted_friends_count&quot; &quot;quoted_statuses_count&quot; [43] &quot;quoted_location&quot; &quot;quoted_description&quot; [45] &quot;quoted_verified&quot; &quot;retweet_status_id&quot; [47] &quot;retweet_text&quot; &quot;retweet_created_at&quot; [49] &quot;retweet_source&quot; &quot;retweet_favorite_count&quot; [51] &quot;retweet_retweet_count&quot; &quot;retweet_user_id&quot; [53] &quot;retweet_screen_name&quot; &quot;retweet_name&quot; [55] &quot;retweet_followers_count&quot; &quot;retweet_friends_count&quot; [57] &quot;retweet_statuses_count&quot; &quot;retweet_location&quot; [59] &quot;retweet_description&quot; &quot;retweet_verified&quot; [61] &quot;place_url&quot; &quot;place_name&quot; [63] &quot;place_full_name&quot; &quot;place_type&quot; [65] &quot;country&quot; &quot;country_code&quot; [67] &quot;geo_coords&quot; &quot;coords_coords&quot; [69] &quot;bbox_coords&quot; &quot;status_url&quot; [71] &quot;name&quot; &quot;location&quot; [73] &quot;description&quot; &quot;url&quot; [75] &quot;protected&quot; &quot;followers_count&quot; [77] &quot;friends_count&quot; &quot;listed_count&quot; [79] &quot;statuses_count&quot; &quot;favourites_count&quot; [81] &quot;account_created_at&quot; &quot;verified&quot; [83] &quot;profile_url&quot; &quot;profile_expanded_url&quot; [85] &quot;account_lang&quot; &quot;profile_banner_url&quot; [87] &quot;profile_background_url&quot; &quot;profile_image_url&quot; So you could spend a lot of time reviewing this information and you probably should if you want to mine Twitter for stuff. Let’s look at the user names of the people who tweeted about COPD. copd_tweets$screen_name [1] &quot;YouThisMe&quot; &quot;ATS_GG&quot; &quot;JayVFight&quot; [4] &quot;GKA_field&quot; &quot;ForaCareUSA&quot; &quot;littlelisa3579&quot; [7] &quot;COPD_research&quot; &quot;COPD_research&quot; &quot;COPD_research&quot; [10] &quot;COPD_research&quot; &quot;COPD_research&quot; &quot;COPD_research&quot; [13] &quot;COPD_research&quot; &quot;COPD_research&quot; &quot;COPD_research&quot; [16] &quot;COPD_research&quot; &quot;COPD_research&quot; &quot;COPD_research&quot; [19] &quot;COPD_research&quot; &quot;COPD_research&quot; &quot;COPD_research&quot; [22] &quot;COPD_research&quot; &quot;COPD_research&quot; &quot;COPD_research&quot; [25] &quot;COPD_research&quot; &quot;COPD_research&quot; &quot;COPD_research&quot; [28] &quot;COPD_research&quot; &quot;COPD_research&quot; &quot;rch4him&quot; [31] &quot;ACMeinde&quot; &quot;efrasanchez&quot; &quot;efrasanchez&quot; [34] &quot;efrasanchez&quot; &quot;myCOPDteam&quot; &quot;ATS_BSHSR&quot; [37] &quot;AllergyAsthmaHQ&quot; &quot;guillesole3&quot; &quot;hgosker&quot; [40] &quot;MaryGreerMurder&quot; &quot;SmartVestSystem&quot; &quot;patosidro&quot; [43] &quot;Sandip_Thakrar&quot; &quot;TheCQRC&quot; &quot;CaliDiet&quot; [46] &quot;GetPalliative&quot; &quot;HildaRosaCarta1&quot; &quot;IARETUSA&quot; [49] &quot;DrMajzun&quot; &quot;ChrisCarrollMD&quot; &quot;accpchest&quot; [52] &quot;CResnews&quot; &quot;MorphCLtd&quot; &quot;COPDCanada&quot; [55] &quot;DialysisSaves&quot; &quot;FABIOVARON&quot; &quot;Donicme&quot; [58] &quot;DemFromCT&quot; &quot;mariaalerey&quot; &quot;ChronicRights&quot; [61] &quot;virenkaul&quot; &quot;atscommunity&quot; &quot;eczemasupport&quot; [64] &quot;BENESG&quot; &quot;DAMiD_Presse&quot; &quot;datadrivencare&quot; [67] &quot;caring_mobile&quot; &quot;RFalfanV&quot; &quot;r2guidance&quot; [70] &quot;EverFLO_Q_OPI&quot; &quot;EverFLO_Q_OPI&quot; &quot;CCI_Ltd&quot; [73] &quot;Sergioblasco68&quot; &quot;trinity_delta&quot; &quot;Nurse_JSW&quot; [76] &quot;LiddleCarol&quot; &quot;pulmonology101&quot; &quot;cristineeberry&quot; [79] &quot;Ms_MMM_Herbert&quot; &quot;AnnieBruton&quot; &quot;jt_resp_physio&quot; [82] &quot;_RichardPalmer&quot; &quot;KarenFinnLondon&quot; &quot;russwinn66&quot; [85] &quot;Ilio79&quot; &quot;teraokanozomi&quot; &quot;AnnaFla1268&quot; [88] &quot;PCRSUK&quot; &quot;lunguk&quot; &quot;bullringbash1&quot; [91] &quot;exerciseCOPD&quot; &quot;blfwales&quot; &quot;666Dunst&quot; [94] &quot;Atemwegsliga&quot; &quot;D_mk77&quot; &quot;AJ_MCMLXV&quot; [97] &quot;Health_Editor&quot; &quot;PR_Assembly&quot; &quot;AnaHDeakinQPS&quot; [100] &quot;RespirologyAPSR&quot; 5.8 Cleaning and Tidying Tweets are much “dirtier” than the text we saw associated with the candidate speeches. To make a reasonable attempt at analyzing them in any way we will need to eliminate URLs and special characters. Consider this tweet. It’s really messy. The rtweet package has a function called plain_tweets that allows one to strip out some of the junk [98] &quot;Work from our own @suryapbhatt and fearless leader @realmdransfield on video #telehealth #cardiopulmonary #rehabilitation and reduction in #COPD readmissions. \\n\\n#gamechanger #UABeMedicine \\n\\nhttps://t.co/6XxIT14bSs\\n\\n@pulmonary_rehab @MTMaddocks @atscommunity @uabmedicine \\n@RKalhan&quot; # plain_tweets(rawt) -&gt; out [1] &quot;Work from our own @suryapbhatt and fearless leader @realmdransfield on video #telehealth #cardiopulmonary #rehabilitation and reduction in #COPD readmissions. #gamechanger #UABeMedicine //t.co/6XxIT14bSs @pulmonary_rehab @MTMaddocks @atscommunity @uabmedicine @RKalhan&quot; Let’s eliminate a lot of junk library(stringr) out &lt;- &quot;Work from our own @suryapbhatt and fearless leader @realmdransfield on video #telehealth #cardiopulmonary #rehabilitation and reduction in #COPD readmissions. #gamechanger #UABeMedicine //t.co/6XxIT14bSs @pulmonary_rehab @MTMaddocks @atscommunity @uabmedicine @RKalhan&quot; #get rid of unnecessary spaces clean_tweet &lt;- str_replace_all(out,&quot; &quot;,&quot; &quot;) # Get rid of URLs clean_tweet &lt;- str_replace_all(clean_tweet, &quot;https://t.co/[a-z,A-Z,0-9]*&quot;,&quot;&quot;) clean_tweet &lt;- str_replace_all(clean_tweet, &quot;http://t.co/[a-z,A-Z,0-9]*&quot;,&quot;&quot;) clean_tweet &lt;- str_replace_all(clean_tweet, &quot;//t.co/[a-z,A-Z,0-9]*&quot;,&quot;&quot;) # Take out retweet header, there is only one clean_tweet &lt;- str_replace(clean_tweet,&quot;RT @[a-z,A-Z]*: &quot;,&quot;&quot;) # Get rid of hashtags clean_tweet &lt;- str_replace_all(clean_tweet,&quot;#[a-z,A-Z]*&quot;,&quot;&quot;) # Get rid of references to other screennames clean_tweet &lt;- str_replace_all(clean_tweet,&quot;@[a-z,A-Z]*&quot;,&quot;&quot;) # Get rid of newlines clean_tweet &lt;- str_replace_all(clean_tweet,&quot;\\n&quot;,&quot;&quot;) # Get rid of underscores clean_tweet &lt;- str_replace_all(clean_tweet,&quot;_&quot;,&quot;&quot;) Now let’s look at the output. Much better clean_tweet [1] &quot;Work from our own and fearless leader on video and reduction in readmissions. rehab &quot; We could then apply this our raw COPD tweets library(stringr) out &lt;- raw_tweets #get rid of unnecessary spaces clean_tweet &lt;- str_replace_all(out,&quot; &quot;,&quot; &quot;) # Get rid of URLs clean_tweet &lt;- str_replace_all(clean_tweet, &quot;https://t.co/[a-z,A-Z,0-9]*&quot;,&quot;&quot;) clean_tweet &lt;- str_replace_all(clean_tweet, &quot;http://t.co/[a-z,A-Z,0-9]*&quot;,&quot;&quot;) clean_tweet &lt;- str_replace_all(clean_tweet, &quot;//t.co/[a-z,A-Z,0-9]*&quot;,&quot;&quot;) # Take out retweet header, there is only one clean_tweet &lt;- str_replace(clean_tweet,&quot;RT @[a-z,A-Z]*: &quot;,&quot;&quot;) # Get rid of hashtags clean_tweet &lt;- str_replace_all(clean_tweet,&quot;#[a-z,A-Z]*&quot;,&quot;&quot;) # Get rid of references to other screennames clean_tweet &lt;- str_replace_all(clean_tweet,&quot;@[a-z,A-Z]*&quot;,&quot;&quot;) # Get rid of newlines clean_tweet &lt;- str_replace_all(clean_tweet,&quot;\\n&quot;,&quot;&quot;) # Get rid of underscores clean_tweet &lt;- str_replace_all(clean_tweet,&quot;_&quot;,&quot;&quot;) Next we’ll create a data frame and then tokenize the COPD tweets copd_df &lt;- tibble(line=1:length(clean_tweet),text=clean_tweet) # Next we&#39;ll tokenize them tidy_copd_df &lt;- copd_df %&gt;% unnest_tokens(word,text) tidy_copd_df &lt;- tidy_copd_df %&gt;% anti_join(stop_words) tidy_copd_df # A tibble: 26,103 x 2 line word &lt;int&gt; &lt;chr&gt; 1 1 6 2 1 haha 3 1 final 4 1 understand 5 1 copd 6 1 asthma 7 1 neurologic 8 1 psychiatric 9 1 disorders 10 1 addiction 5.9 Make The Word Cloud tidy_copd_df_table &lt;- tidy_copd_df %&gt;% count(word, sort = TRUE) tidy_copd_df_table # https://www.littlemissdata.com/blog/wordclouds wordcloud2(tidy_copd_df_table,size=0.7) Let’s try that again because the word copd dominates the cloud. swords &lt;- c(&quot;copd&quot;,&quot;patients&quot;,&quot;disease&quot;,&quot;health&quot;,&quot;chronic&quot;, &quot;pulmonary&quot;,&quot;obstructive&quot;,&quot;lung&quot;,&quot;1&quot;,&quot;2&quot;) tidy_copd_df_table &lt;- tidy_copd_df_table %&gt;% filter(!word %in% swords) wordcloud2(tidy_copd_df_table,size=0.7) 5.10 Bi-Grams copd_df &lt;- tibble(line=1:length(clean_tweet),text=clean_tweet) # Next we&#39;ll tokenize them bi_tidy_copd_df &lt;- copd_df %&gt;% unnest_tokens(paired_words,text,token = &quot;ngrams&quot;, n = 2) bi_tidy_copd_df %&gt;% count(paired_words, sort = TRUE) # bi_tidy_copd_df_separated_words &lt;- bi_tidy_copd_df %&gt;% separate(paired_words, c(&quot;word1&quot;, &quot;word2&quot;), sep = &quot; &quot;) swords &lt;- c(&quot;copd&quot;,&quot;patients&quot;,&quot;disease&quot;,&quot;health&quot;,&quot;chronic&quot;, &quot;pulmonary&quot;,&quot;obstructive&quot;,&quot;lung&quot;,&quot;1&quot;,&quot;2&quot;) bi_copd_tweets_filtered &lt;- bi_tidy_copd_df_separated_words %&gt;% filter(!word1 %in% c(stop_words$word,swords)) %&gt;% filter(!word2 %in% c(stop_words$word,swords)) &gt; bi_copd_tweets_filtered # A tibble: 9,078 x 3 line word1 word2 &lt;int&gt; &lt;chr&gt; &lt;chr&gt; 1 1 6 haha 2 1 psychiatric disorders 3 1 disorders addiction 4 1 addiction pain 5 1 infectious diseases 6 3 run speed 7 3 speed walk 8 3 walk cycle 9 3 cycle workout 10 3 canada army # … with 9,068 more rows copd_bi_words_counts &lt;- bi_copd_tweets_filtered %&gt;% count(word1,word2,sort=TRUE) &gt; copd_bi_words_counts # A tibble: 7,388 x 3 word1 word2 n &lt;chr&gt; &lt;chr&gt; &lt;int&gt; 1 wearables trial 24 2 eu patent 20 3 heart failure 19 4 phase 3 15 5 3 data 14 6 immunization program 14 7 maternal immunization 14 8 program phase 14 9 quit smoking 14 10 rsv maternal 14 # … with 7,378 more rows # library(igraph) library(ggraph) copd_bi_words_counts %&gt;% filter(n &gt;= 10) %&gt;% graph_from_data_frame() %&gt;% ggraph(layout = &quot;fr&quot;) + geom_edge_link(aes(edge_alpha = n, edge_width = n)) + geom_node_point(color = &quot;darkslategray4&quot;, size = 3) + geom_node_text(aes(label = name), vjust = 1.8, size = 3) + labs(title = &quot;Word Network: Tweets using the hashtag - COPD&quot;, subtitle = &quot;Text mining twitter data &quot;, x = &quot;&quot;, y = &quot;&quot;) "]
]
